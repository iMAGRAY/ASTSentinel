{"session_id":"2196d520-5b1c-4893-9ea0-223ccab0bc49","transcript_path":"C:\\Users\\1\\.claude\\projects\\C--Users-1-Documents-GitHub-ValidationCodeHook\\2196d520-5b1c-4893-9ea0-223ccab0bc49.jsonl","cwd":"C:\\Users\\1\\Documents\\GitHub\\ValidationCodeHook","permission_mode":"bypassPermissions","hook_event_name":"PostToolUse","tool_name":"Edit","tool_input":{"file_path":"src/bin/pretooluse.rs","old_string":"    let combined_new = new_opt.clone().unwrap_or_default();\n    assess.is_return_constant_only = detect_return_constant(&combined_new);\n    assess.is_print_or_log_only = detect_print_only(&combined_new);\n    // NOTE: we no дольше блокируем TODO/FIXME как таковые; оставляем для сводки\n    assess.has_todo_or_placeholder = detect_todo_placeholder(&combined_new);\n    assess.has_empty_catch_or_except = detect_empty_catch_except(&combined_new);\n    // Проверяем молчаливый discard результатов (сравнение старого и нового кода)\n    if old_opt.is_some() && new_opt.is_some() {\n        assess.has_silent_result_discard = detect_silent_result_discard(&combined_old, &combined_new);\n    }","new_string":"    let combined_old = old_opt.clone().unwrap_or_default();\n    let combined_new = new_opt.clone().unwrap_or_default();\n    assess.is_return_constant_only = detect_return_constant(&combined_new);\n    assess.is_print_or_log_only = detect_print_only(&combined_new);\n    // NOTE: we no дольше блокируем TODO/FIXME как таковые; оставляем для сводки\n    assess.has_todo_or_placeholder = detect_todo_placeholder(&combined_new);\n    assess.has_empty_catch_or_except = detect_empty_catch_except(&combined_new);\n    // Проверяем молчаливый discard результатов (сравнение старого и нового кода)\n    if old_opt.is_some() && new_opt.is_some() {\n        assess.has_silent_result_discard = detect_silent_result_discard(&combined_old, &combined_new);\n    }"},"tool_response":{"filePath":"src/bin/pretooluse.rs","oldString":"    let combined_new = new_opt.clone().unwrap_or_default();\n    assess.is_return_constant_only = detect_return_constant(&combined_new);\n    assess.is_print_or_log_only = detect_print_only(&combined_new);\n    // NOTE: we no дольше блокируем TODO/FIXME как таковые; оставляем для сводки\n    assess.has_todo_or_placeholder = detect_todo_placeholder(&combined_new);\n    assess.has_empty_catch_or_except = detect_empty_catch_except(&combined_new);\n    // Проверяем молчаливый discard результатов (сравнение старого и нового кода)\n    if old_opt.is_some() && new_opt.is_some() {\n        assess.has_silent_result_discard = detect_silent_result_discard(&combined_old, &combined_new);\n    }","newString":"    let combined_old = old_opt.clone().unwrap_or_default();\n    let combined_new = new_opt.clone().unwrap_or_default();\n    assess.is_return_constant_only = detect_return_constant(&combined_new);\n    assess.is_print_or_log_only = detect_print_only(&combined_new);\n    // NOTE: we no дольше блокируем TODO/FIXME как таковые; оставляем для сводки\n    assess.has_todo_or_placeholder = detect_todo_placeholder(&combined_new);\n    assess.has_empty_catch_or_except = detect_empty_catch_except(&combined_new);\n    // Проверяем молчаливый discard результатов (сравнение старого и нового кода)\n    if old_opt.is_some() && new_opt.is_some() {\n        assess.has_silent_result_discard = detect_silent_result_discard(&combined_old, &combined_new);\n    }","originalFile":"#![cfg_attr(\n    not(test),\n    deny(\n        clippy::unwrap_used,\n        clippy::expect_used,\n        clippy::panic,\n        clippy::todo,\n        clippy::unimplemented,\n        clippy::dbg_macro\n    )\n)]\n#![allow(clippy::items_after_test_module)]\nuse anyhow::{Context, Result};\nuse std::fs::File;\nuse std::io::{self, Read};\n\nuse rust_validation_hooks::analysis::ast::{MultiLanguageAnalyzer, SupportedLanguage};\nuse rust_validation_hooks::analysis::dependencies::analyze_project_dependencies;\nuse rust_validation_hooks::analysis::project::{\n    format_project_structure_for_ai, scan_project_structure, ScanConfig,\n};\nuse rust_validation_hooks::*;\n// Use universal AI client\nuse rust_validation_hooks::providers::ai::UniversalAIClient;\n// Test file validator removed - AI handles validation\n// Use diff formatter for better AI context\nuse rust_validation_hooks::config;\nuse rust_validation_hooks::validation::diff_formatter::{\n    format_code_diff, format_edit_diff, format_multi_edit_diff,\n};\n\n#[inline]\nfn dev_flag_enabled(name: &str) -> bool {\n    #[cfg(debug_assertions)]\n    {\n        match std::env::var(name) {\n            Ok(v) => v != \"0\" && !v.is_empty(),\n            Err(_) => false,\n        }\n    }\n    #[cfg(not(debug_assertions))]\n    {\n        let _ = name;\n        false\n    }\n}\n// =============================\n// Heuristics for anti-cheating\n// =============================\n#[derive(Default, Debug)]\nstruct HeuristicAssessment {\n    is_whitespace_or_comments_only: bool,\n    is_return_constant_only: bool,\n    is_print_or_log_only: bool,\n    has_todo_or_placeholder: bool,\n    has_empty_catch_or_except: bool,\n    is_new_file_minimal: bool,\n    // Stronger signals to reduce ложные срабатывания\n    const_return_ignores_params: bool,\n    logic_calls_removed: bool,\n    // Контекст, где минимальная реализация допустима (версия/здоровье/ping)\n    is_allowed_minimal_context: bool,\n    has_silent_result_discard: bool,\n    summary: String,\n}\n\n// ==============\n// API Contract heuristics (regex-based; Python/JS/TS)\n// ==============\nfn extract_signatures_regex(\n    language: Option<SupportedLanguage>,\n    code: &str,\n) -> std::collections::HashMap<String, Vec<String>> {\n    use regex::Regex;\n    let mut map = std::collections::HashMap::new();\n    let Some(lang) = language else {\n        return map;\n    };\n    match lang {\n        SupportedLanguage::Python => {\n            if let Ok(re) = Regex::new(r\"(?m)^\\s*def\\s+([A-Za-z_][A-Za-z0-9_]*)\\s*\\(([^)]*)\\)\") {\n                for cap in re.captures_iter(code) {\n                    let name = cap.get(1).map(|m| m.as_str()).unwrap_or(\"\").to_string();\n                    let params = cap.get(2).map(|m| m.as_str()).unwrap_or(\"\");\n                    let list = params\n                        .split(',')\n                        .map(|p| p.trim())\n                        .filter(|p| !p.is_empty())\n                        .map(|p| {\n                            let base = p\n                                .split(':')\n                                .next()\n                                .unwrap_or(\"\")\n                                .split('=')\n                                .next()\n                                .unwrap_or(\"\")\n                                .trim();\n                            base.trim_start_matches('*').to_string()\n                        })\n                        .filter(|p| !matches!(p.as_str(), \"self\" | \"cls\" | \"args\" | \"kwargs\"))\n                        .collect::<Vec<_>>();\n                    if !name.is_empty() {\n                        map.insert(name, list);\n                    }\n                }\n            }\n        }\n        SupportedLanguage::JavaScript | SupportedLanguage::TypeScript => {\n            if let Ok(re_fn) = Regex::new(r\"(?m)function\\s+([A-Za-z_][A-Za-z0-9_]*)\\s*\\(([^)]*)\\)\") {\n                for cap in re_fn.captures_iter(code) {\n                    let name = cap.get(1).map(|m| m.as_str()).unwrap_or(\"\").to_string();\n                    let params = cap.get(2).map(|m| m.as_str()).unwrap_or(\"\");\n                    let list = params\n                        .split(',')\n                        .map(|p| p.trim())\n                        .filter(|p| !p.is_empty())\n                        .map(|p| {\n                            p.trim_start_matches(\"...\")\n                                .split(':')\n                                .next()\n                                .unwrap_or(\"\")\n                                .trim_end_matches('?')\n                                .to_string()\n                        })\n                        .collect::<Vec<_>>();\n                    if !name.is_empty() {\n                        map.insert(name, list);\n                    }\n                }\n            }\n            // Class methods: name(param){ ... }\n            if let Ok(re_m) = Regex::new(r\"(?m)^\\s*([A-Za-z_][A-Za-z0-9_]*)\\s*\\(([^)]*)\\)\\s*\\{\") {\n                for cap in re_m.captures_iter(code) {\n                    let name = cap.get(1).map(|m| m.as_str()).unwrap_or(\"\").to_string();\n                    let params = cap.get(2).map(|m| m.as_str()).unwrap_or(\"\");\n                    let list = params\n                        .split(',')\n                        .map(|p| p.trim())\n                        .filter(|p| !p.is_empty())\n                        .map(|p| {\n                            p.trim_start_matches(\"...\")\n                                .split(':')\n                                .next()\n                                .unwrap_or(\"\")\n                                .to_string()\n                        })\n                        .collect::<Vec<_>>();\n                    if !name.is_empty() {\n                        map.entry(name).or_insert(list.clone());\n                    }\n                }\n            }\n        }\n        _ => {}\n    }\n    map\n}\n\nfn contract_weakening_reasons(\n    language: Option<SupportedLanguage>,\n    old_code: &str,\n    new_code: &str,\n) -> Vec<String> {\n    let before = extract_signatures_regex(language, old_code);\n    let after = extract_signatures_regex(language, new_code);\n    if before.is_empty() && after.is_empty() {\n        return vec![];\n    }\n    let mut reasons = Vec::new();\n    for (name, bparams) in before.iter() {\n        if let Some(aparams) = after.get(name) {\n            if aparams.len() < bparams.len() {\n                reasons.push(format!(\n                    \"Function `{}`: parameter count reduced ({} -> {})\",\n                    name,\n                    bparams.len(),\n                    aparams.len()\n                ));\n            } else {\n                for bp in bparams {\n                    if !bp.is_empty() && !aparams.iter().any(|x| x == bp) {\n                        reasons.push(format!(\n                            \"Function `{}`: parameter `{}` removed or renamed\",\n                            name, bp\n                        ));\n                    }\n                }\n            }\n        } else {\n            reasons.push(format!(\"Function `{}`: removed from module\", name));\n        }\n    }\n    reasons\n}\n\n// Heuristic: find call sites that still pass removed parameters or exceed new\n// arity\nfn find_contract_callsite_issues(\n    language: Option<SupportedLanguage>,\n    old_code: &str,\n    new_code: &str,\n) -> Vec<String> {\n    use std::collections::HashMap;\n    let lang = language;\n    let before = extract_signatures_regex(lang, old_code);\n    let after = extract_signatures_regex(lang, new_code);\n    let mut issues = Vec::new();\n\n    // Helper: count top-level args and detect named args in a slice\n    fn analyze_args_slice(slice: &str) -> (usize, Vec<String>) {\n        let mut depth = 0usize;\n        let mut count = 0usize;\n        let mut named = Vec::new();\n        let mut token = String::new();\n        let mut i = 0;\n        let bytes = slice.as_bytes();\n        while i < bytes.len() {\n            let c = bytes[i] as char;\n            match c {\n                '(' | '[' | '{' => {\n                    depth += 1;\n                    token.clear();\n                }\n                ')' | ']' | '}' => {\n                    depth = depth.saturating_sub(1);\n                }\n                ',' => {\n                    if depth == 0 {\n                        count += 1;\n                        token.clear();\n                    }\n                }\n                '=' => {\n                    if depth == 0 {\n                        let name = token.trim();\n                        if !name.is_empty() {\n                            named.push(name.to_string());\n                        }\n                    }\n                }\n                _ => {\n                    if depth == 0 {\n                        token.push(c);\n                    }\n                }\n            }\n            i += 1;\n        }\n        // If non-empty args without trailing comma, increment count\n        let trimmed = slice.trim();\n        if !trimmed.is_empty() {\n            count = count.saturating_add(1);\n        }\n        (count, named)\n    }\n\n    // Extract removed signatures\n    let mut removed_params: HashMap<String, Vec<String>> = HashMap::new();\n    let mut reduced_arity: HashMap<String, (usize, usize)> = HashMap::new();\n    for (name, bparams) in before.iter() {\n        if let Some(aparams) = after.get(name) {\n            if aparams.len() < bparams.len() {\n                reduced_arity.insert(name.clone(), (bparams.len(), aparams.len()));\n            }\n            let mut removed = Vec::new();\n            for bp in bparams {\n                // Python boilerplate ignore\n                if matches!(lang, Some(SupportedLanguage::Python))\n                    && (bp == \"self\" || bp == \"cls\" || bp == \"args\" || bp == \"kwargs\")\n                {\n                    continue;\n                }\n                if !bp.is_empty() && !aparams.iter().any(|x| x == bp) {\n                    removed.push(bp.clone());\n                }\n            }\n            if !removed.is_empty() {\n                removed_params.insert(name.clone(), removed);\n            }\n        } else {\n            // Function removed entirely — flag\n            issues.push(format!(\"Function `{}` removed; consider migration plan\", name));\n        }\n    }\n\n    if removed_params.is_empty() && reduced_arity.is_empty() {\n        return issues;\n    }\n\n    let code = new_code;\n    // Scan for function calls by name (simple heuristic)\n    for (fname, removed) in removed_params.iter() {\n        let mut pos = 0usize;\n        let mut seen_named = Vec::new();\n        while let Some(idx) = code[pos..].find(fname) {\n            let i = pos + idx;\n            // ensure word boundary and next char is '('\n            if i > 0 {\n                let prev = code.as_bytes()[i - 1] as char;\n                if prev.is_ascii_alphanumeric() || prev == '_' {\n                    pos = i + fname.len();\n                    continue;\n                }\n            }\n            let after = i + fname.len();\n            let tail = &code[after..];\n            let open = tail.find('(');\n            if let Some(op) = open {\n                let j = after + op + 1; // position after '('\n                let mut depth = 1i32;\n                let mut end = j;\n                while end < code.len() {\n                    let ch = code.as_bytes()[end] as char;\n                    if ch == '(' {\n                        depth += 1;\n                    } else if ch == ')' {\n                        depth -= 1;\n                        if depth == 0 {\n                            break;\n                        }\n                    }\n                    end += 1;\n                }\n                if depth == 0 && end <= code.len() {\n                    let args_slice = &code[j..end];\n                    let (_argc, named) = analyze_args_slice(args_slice);\n                    for r in removed {\n                        let needle = format!(\"{}=\", r);\n                        if args_slice.contains(&needle) || named.iter().any(|n| n == r) {\n                            seen_named.push(r.clone());\n                        }\n                    }\n                    pos = end + 1;\n                    continue;\n                }\n            }\n            pos = after;\n        }\n        if !seen_named.is_empty() {\n            issues.push(format!(\n                \"Calls to `{fname}` still pass removed named params: {}\",\n                seen_named.join(\", \")\n            ));\n        }\n    }\n\n    for (fname, (old_n, new_n)) in reduced_arity.iter() {\n        let mut pos = 0usize;\n        let mut offending = 0usize;\n        while let Some(idx) = code[pos..].find(fname) {\n            let i = pos + idx;\n            if i > 0 {\n                let prev = code.as_bytes()[i - 1] as char;\n                if prev.is_ascii_alphanumeric() || prev == '_' {\n                    pos = i + fname.len();\n                    continue;\n                }\n            }\n            let after = i + fname.len();\n            let tail = &code[after..];\n            if let Some(op) = tail.find('(') {\n                let j = after + op + 1;\n                let mut depth = 1i32;\n                let mut end = j;\n                while end < code.len() {\n                    let ch = code.as_bytes()[end] as char;\n                    if ch == '(' {\n                        depth += 1;\n                    } else if ch == ')' {\n                        depth -= 1;\n                        if depth == 0 {\n                            break;\n                        }\n                    }\n                    end += 1;\n                }\n                if depth == 0 {\n                    let args_slice = &code[j..end];\n                    let (argc, _) = analyze_args_slice(args_slice);\n                    if argc > *new_n {\n                        offending += 1;\n                    }\n                    pos = end + 1;\n                    continue;\n                }\n            }\n            pos = after;\n        }\n        if offending > 0 {\n            issues.push(format!(\n                \"Calls to `{}` exceed new arity ({} -> {}): {} occurrences\",\n                fname, old_n, new_n, offending\n            ));\n        }\n    }\n\n    issues\n}\n\nfn extract_old_new_contents(hook_input: &HookInput) -> (String, Option<String>, Option<String>) {\n    let file_path = extract_file_path(&hook_input.tool_input);\n    match hook_input.tool_name.as_str() {\n        \"Edit\" => {\n            let old = hook_input\n                .tool_input\n                .get(\"old_string\")\n                .and_then(|v| v.as_str())\n                .map(|s| s.to_string());\n            let new = hook_input\n                .tool_input\n                .get(\"new_string\")\n                .and_then(|v| v.as_str())\n                .map(|s| s.to_string());\n            (file_path, old, new)\n        }\n        \"MultiEdit\" => {\n            if let Some(edits) = hook_input.tool_input.get(\"edits\").and_then(|v| v.as_array()) {\n                let mut old = String::new();\n                let mut new = String::new();\n                for e in edits.iter().take(1000) {\n                    if let Some(o) = e.get(\"old_string\").and_then(|v| v.as_str()) {\n                        old.push_str(o);\n                        old.push('\\n');\n                    }\n                    if let Some(n) = e.get(\"new_string\").and_then(|v| v.as_str()) {\n                        new.push_str(n);\n                        new.push('\\n');\n                    }\n                }\n                (\n                    file_path,\n                    if old.is_empty() { None } else { Some(old) },\n                    if new.is_empty() { None } else { Some(new) },\n                )\n            } else {\n                let old = std::fs::read_to_string(&file_path).ok();\n                (file_path, old, None)\n            }\n        }\n        \"Write\" => {\n            let old = std::fs::read_to_string(&file_path).ok();\n            let new = hook_input\n                .tool_input\n                .get(\"content\")\n                .and_then(|v| v.as_str())\n                .map(|s| s.to_string());\n            (file_path, old, new)\n        }\n        _ => (file_path, None, None),\n    }\n}\n\n// -----------------\n// Unit tests (private) for contract heuristics\n// -----------------\n#[cfg(test)]\nmod tests {\n    use super::{\n        contract_weakening_reasons, detect_function_stub, detect_return_constant, extract_signatures_regex,\n    };\n    use rust_validation_hooks::analysis::ast::SupportedLanguage;\n\n    #[test]\n    fn unit_contract_detects_python_param_reduction() {\n        let old = \"def f(a, b):\\n    return a + b\\n\";\n        let new = \"def f(a):\\n    return a\\n\";\n        let reasons = contract_weakening_reasons(Some(SupportedLanguage::Python), old, new);\n        assert!(!reasons.is_empty(), \"expected contract weakening reasons\");\n        assert!(reasons.iter().any(|r| r.contains(\"parameter count reduced\")));\n    }\n\n    #[test]\n    fn unit_contract_preserves_js_same_signature() {\n        let old = \"function sum(a, b){ return a + b }\\n\";\n        let new = \"function sum(a, b){ const c = a + b; return c }\\n\";\n        // сигнатуры одинаковые → пусто\n        let reasons = contract_weakening_reasons(Some(SupportedLanguage::JavaScript), old, new);\n        assert!(reasons.is_empty(), \"no weakening expected for same signature\");\n        // sanity: разбор сигнатур видит два параметра\n        let sig_old = extract_signatures_regex(Some(SupportedLanguage::JavaScript), old);\n        assert_eq!(sig_old.get(\"sum\").map(|v| v.len()), Some(2));\n    }\n\n    #[test]\n    fn unit_detects_return_constant_python() {\n        let code = \"def f(x):\\n    return 1\\n\";\n        assert!(\n            detect_return_constant(code),\n            \"should detect return literal in python\"\n        );\n    }\n\n    #[test]\n    fn unit_detects_return_constant_js() {\n        let code = \"function f(){ return true; }\";\n        assert!(detect_return_constant(code), \"should detect return literal in js\");\n    }\n\n    #[test]\n    fn unit_detects_function_stub_python_pass() {\n        let code = \"def f(x):\\n    # TODO\\n    pass\\n\";\n        assert!(\n            detect_function_stub(Some(SupportedLanguage::Python), code),\n            \"should detect python pass stub\"\n        );\n    }\n\n    #[test]\n    fn unit_detects_function_stub_js_throw() {\n        let code = \"function f(){ throw new Error('Not implemented'); }\";\n        assert!(\n            detect_function_stub(Some(SupportedLanguage::JavaScript), code),\n            \"should detect js throw Not implemented stub\"\n        );\n    }\n}\n\nfn normalize_code_for_signal(code: &str) -> String {\n    let mut s = String::new();\n    let mut i = 0;\n    let b = code.as_bytes();\n    while i < b.len() {\n        if i + 1 < b.len() && b[i] == b'/' && b[i + 1] == b'*' {\n            i += 2;\n            while i + 1 < b.len() && !(b[i] == b'*' && b[i + 1] == b'/') {\n                i += 1;\n            }\n            if i + 1 < b.len() {\n                i += 2;\n            }\n            continue;\n        }\n        if i + 1 < b.len() && b[i] == b'/' && b[i + 1] == b'/' {\n            while i < b.len() && b[i] != b'\\n' {\n                i += 1;\n            }\n            continue;\n        }\n        if b[i] == b'#' {\n            while i < b.len() && b[i] != b'\\n' {\n                i += 1;\n            }\n            continue;\n        }\n        s.push(b[i] as char);\n        i += 1;\n    }\n    s.split_whitespace().collect::<Vec<_>>().join(\"\")\n}\n\nfn detect_return_constant(code: &str) -> bool {\n    use once_cell::sync::Lazy;\n    // Match: return <literal>  where literal is number/bool/null/none or quoted\n    // string.\n    static RET_RE: Lazy<Result<regex::Regex, regex::Error>> = Lazy::new(|| {\n        // Match return literal anywhere on the line (not only at start)\n        regex::Regex::new(r#\"(?i)\\breturn\\s+(?:\\d+|true|false|null|none|\\\"[^\\\"]*\\\"|'[^']*')\\s*(?:;|[,})]|$)\"#)\n    });\n    // Match arrow functions that immediately return a literal:  => <literal>\n    static ARROW_RE: Lazy<Result<regex::Regex, regex::Error>> = Lazy::new(|| {\n        regex::Regex::new(r#\"=>\\s*(?:\\d+|true|false|null|none|\\\"[^\\\"]*\\\"|'[^']*')\\s*(?:[,)};]|$)\"#)\n    });\n    if let Ok(re) = RET_RE.as_ref() {\n        if re.is_match(code) {\n            return true;\n        }\n    }\n    if let Ok(re) = ARROW_RE.as_ref() {\n        if re.is_match(code) {\n            return true;\n        }\n    }\n    false\n}\n\nfn detect_js_ts_function_stub(code: &str) -> bool {\n    use regex::Regex;\n    if let Ok(re) = Regex::new(\n        r#\"(?i)\\bthrow\\s+new\\s+Error\\s*\\(\\s*['\\\"][^'\\\"]*(not\\s+implemented|todo)[^'\\\"]*['\\\"]\\s*\\)\"#,\n    ) {\n        if re.is_match(code) {\n            return true;\n        }\n    }\n    if let Ok(re) =\n        Regex::new(r#\"(?s)function\\s+[A-Za-z_][A-Za-z0-9_]*\\s*\\([^)]*\\)\\s*\\{\\s*(/\\*.*?\\*/|//.*?\\n|\\s)*\\}\"#)\n    {\n        if re.is_match(code) {\n            return true;\n        }\n    }\n    if let Ok(re) =\n        Regex::new(r#\"(?s)^[ \\t]*[A-Za-z_][A-Za-z0-9_]*\\s*\\([^)]*\\)\\s*\\{\\s*(/\\*.*?\\*/|//.*?\\n|\\s)*\\}$\"#)\n    {\n        if re.is_match(code) {\n            return true;\n        }\n    }\n    false\n}\n\nfn detect_python_function_stub(code: &str) -> bool {\n    use regex::Regex;\n    if let Ok(re) =\n        Regex::new(r#\"(?sm)^\\s*def\\s+[A-Za-z_][A-Za-z0-9_]*\\s*\\([^)]*\\):\\s*(?:#.*\\n|\\s)*pass\\s*$\"#)\n    {\n        if re.is_match(code) {\n            return true;\n        }\n    }\n    if let Ok(re) = Regex::new(\n        r#\"(?sm)^\\s*def\\s+[A-Za-z_][A-Za-z0-9_]*\\s*\\([^)]*\\):\\s*(?:#.*\\n|\\s)*raise\\s+NotImplementedError\\b[^\\n]*$\"#,\n    ) {\n        if re.is_match(code) {\n            return true;\n        }\n    }\n    false\n}\n\nfn detect_function_stub(language: Option<SupportedLanguage>, code: &str) -> bool {\n    match language {\n        Some(SupportedLanguage::Python) => detect_python_function_stub(code),\n        Some(SupportedLanguage::JavaScript) | Some(SupportedLanguage::TypeScript) => {\n            detect_js_ts_function_stub(code)\n        }\n        _ => false,\n    }\n}\n\n#[inline]\nfn detect_print_only(code: &str) -> bool {\n    let low = code.to_ascii_lowercase();\n    // Fast precheck: any known print/log patterns?\n    const TOKENS: [&str; 5] = [\n        \"console.log(\",\n        \"print(\",\n        \"logger.\",\n        \"system.out.println(\",\n        \"debug(\",\n    ];\n    if !TOKENS.iter().any(|t| low.contains(t)) {\n        return false;\n    }\n    // Count alphanumeric characters while skipping known tokens to avoid allocation\n    let bytes = low.as_bytes();\n    let mut i = 0usize;\n    let mut alnum = 0usize;\n    while i < bytes.len() {\n        // Try to skip a known token at current offset\n        let mut skipped = false;\n        for t in TOKENS {\n            let tb = t.as_bytes();\n            if i + tb.len() <= bytes.len() && &bytes[i..i + tb.len()] == tb {\n                i += tb.len();\n                skipped = true;\n                break;\n            }\n        }\n        if skipped {\n            continue;\n        }\n        let c = bytes[i] as char;\n        if c.is_ascii_alphanumeric() {\n            alnum += 1;\n        }\n        i += 1;\n    }\n    alnum < 6\n}\n\nfn detect_todo_placeholder(code: &str) -> bool {\n    let low = code.to_ascii_lowercase();\n    low.contains(\"todo\") || low.contains(\"fixme\") || low.contains(\"notimplemented\") || low.contains(\"pass\\n\")\n}\n\nfn detect_empty_catch_except(code: &str) -> bool {\n    let low = code.to_ascii_lowercase();\n\n    // Удаляем все пробельные символы для точной проверки\n    let compact: String = low.chars().filter(|c| !c.is_whitespace()).collect();\n\n    // Java/C#/JS: catch(любое_исключение){} или catch(любое_исключение){}\n    // Проверяем есть ли catch блок с пустым телом\n    if compact.contains(\"catch(\") {\n        // Ищем паттерн catch(...){} где внутри {} нет кода\n        if let Some(catch_pos) = compact.find(\"catch(\") {\n            if let Some(open_brace) = compact[catch_pos..].find(\"){\") {\n                let after_brace = catch_pos + open_brace + 2;\n                if after_brace < compact.len() && compact.chars().nth(after_brace) == Some('}') {\n                    return true;\n                }\n            }\n        }\n    }\n\n    // Python: except: pass\n    if low.contains(\"except\") && low.contains(\":\") {\n        let except_pass = low.replace('\\n', \" \").replace('\\t', \" \");\n        if except_pass.contains(\"except:\") && except_pass.contains(\"pass\") {\n            // Проверяем что pass идёт сразу после except:\n            if let Some(except_pos) = except_pass.find(\"except:\") {\n                let after_except = &except_pass[except_pos + 7..].trim();\n                if after_except.starts_with(\"pass\") {\n                    return true;\n                }\n            }\n        }\n    }\n\n    // JS/TS: Promise .catch(() => {}) or .catch(function(){})\n    if compact.contains(\".catch(()=>{})\") || compact.contains(\".catch(function(){})\") {\n        return true;\n    }\n\n    false\n}\n\nfn detect_silent_result_discard(old: &str, new: &str) -> bool {\n    // Go: проверяем изменение с обработки ошибки на _ = func()\n    let old_low = old.to_ascii_lowercase();\n    let new_low = new.to_ascii_lowercase();\n\n    // Удаляем пробелы для точного сравнения\n    let old_compact: String = old_low.chars().filter(|c| !c.is_whitespace()).collect();\n    let new_compact: String = new_low.chars().filter(|c| !c.is_whitespace()).collect();\n\n    // Go: было if err := func(); err != nil { ... }, стало _ = func()\n    if old_compact.contains(\"iferr:=\") && old_compact.contains(\"err!=nil\") {\n        if new_compact.contains(\"_=\") && !new_compact.contains(\"iferr:=\") {\n            return true;\n        }\n    }\n\n    false\n}\n\nfn assess_change(hook_input: &HookInput) -> HeuristicAssessment {\n    let (_path, old_opt, new_opt) = extract_old_new_contents(hook_input);\n    let mut assess = HeuristicAssessment::default();\n    if let (Some(old), Some(new)) = (old_opt.as_ref(), new_opt.as_ref()) {\n        let norm_old = normalize_code_for_signal(old);\n        let norm_new = normalize_code_for_signal(new);\n        if norm_old == norm_new {\n            assess.is_whitespace_or_comments_only = true;\n        }\n    }\n    let combined_new = new_opt.clone().unwrap_or_default();\n    assess.is_return_constant_only = detect_return_constant(&combined_new);\n    assess.is_print_or_log_only = detect_print_only(&combined_new);\n    // NOTE: we no дольше блокируем TODO/FIXME как таковые; оставляем для сводки\n    assess.has_todo_or_placeholder = detect_todo_placeholder(&combined_new);\n    assess.has_empty_catch_or_except = detect_empty_catch_except(&combined_new);\n    // Проверяем молчаливый discard результатов (сравнение старого и нового кода)\n    if old_opt.is_some() && new_opt.is_some() {\n        assess.has_silent_result_discard = detect_silent_result_discard(&combined_old, &combined_new);\n    }\n    // New, minimal file creation (do not block for simple stubs like print(\"ok\"))\n    if old_opt.is_none() && new_opt.is_some() {\n        let norm = normalize_code_for_signal(&combined_new);\n        assess.is_new_file_minimal = combined_new.trim().len() <= 64 || norm.len() <= 32;\n    }\n    // Allowed minimal context: version/health/ping endpoints or files\n    let file_path = extract_file_path(&hook_input.tool_input).to_ascii_lowercase();\n    let fname_ok =\n        file_path.contains(\"version\") || file_path.contains(\"health\") || file_path.contains(\"ping\");\n    assess.is_allowed_minimal_context = fname_ok;\n\n    // Stronger signals\n    assess.const_return_ignores_params = detect_const_return_ignores_params(&combined_new);\n    assess.logic_calls_removed = {\n        let old_calls = old_opt.as_ref().map(|s| count_call_like_tokens(s)).unwrap_or(0);\n        let new_calls = count_call_like_tokens(&combined_new);\n        old_calls >= 3 && new_calls == 0 && (assess.is_return_constant_only || assess.is_print_or_log_only)\n    };\n    let mut parts = Vec::new();\n    if assess.is_whitespace_or_comments_only {\n        parts.push(\"no-op change (whitespace/comments only)\".to_string());\n    }\n    if assess.is_return_constant_only {\n        parts.push(\"returns constant only\".to_string());\n    }\n    if assess.is_print_or_log_only {\n        parts.push(\"print/log only\".to_string());\n    }\n    if assess.const_return_ignores_params {\n        parts.push(\"constant return ignores params\".to_string());\n    }\n    if assess.logic_calls_removed {\n        parts.push(\"logic/calls removed\".to_string());\n    }\n    if assess.has_todo_or_placeholder {\n        parts.push(\"TODO present\".to_string());\n    }\n    if assess.has_empty_catch_or_except {\n        parts.push(\"empty catch/except\".to_string());\n    }\n    if assess.has_silent_result_discard {\n        parts.push(\"silent result discard\".to_string());\n    }\n    if assess.is_new_file_minimal {\n        parts.push(\"new minimal file\".to_string());\n    }\n    assess.summary = if parts.is_empty() {\n        \"no red flags\".to_string()\n    } else {\n        parts.join(\", \")\n    };\n    assess\n}\n\n// Heuristic: constant return while parameters exist and are unused\nfn detect_const_return_ignores_params(code: &str) -> bool {\n    use regex::Regex;\n    // Python: def f(a,b): ... return <lit>\n    if let Ok(re) = Regex::new(\n        r#\"(?s)def\\s+[A-Za-z_][A-Za-z0-9_]*\\s*\\(([^)]*[^\\s)])\\)\\s*:\\s*(?:#.*\\n|\\s)*return\\s+(?:\\d+|True|False|None|\"[^\"]*\"|'[^']*')\\b\"#,\n    ) {\n        if let Some(cap) = re.captures(code) {\n            let params = cap.get(1).map(|m| m.as_str()).unwrap_or(\"\");\n            let body_start = cap.get(0).map(|m| m.end()).unwrap_or(0);\n            let body = &code[body_start.saturating_sub(80)..body_start]; // small window is enough\n            let names: Vec<&str> = params\n                .split(',')\n                .map(|p| p.trim())\n                .filter(|p| !p.is_empty())\n                .collect();\n            if !names.is_empty() && !names.iter().any(|n| body.contains(n)) {\n                return true;\n            }\n        }\n    }\n    // JS/TS: function f(a,b){ return <lit>; } or (a,b)=> <lit>\n    if let Ok(re) = Regex::new(\n        r#\"(?s)function\\s+[A-Za-z_][A-Za-z0-9_]*\\s*\\(([^)]*[^\\s)])\\)\\s*\\{\\s*return\\s+(?:\\d+|true|false|null|\"[^\"]*\"|'[^']*')\\s*;?\\s*\\}\"#,\n    ) {\n        if let Some(cap) = re.captures(code) {\n            let params = cap.get(1).map(|m| m.as_str()).unwrap_or(\"\");\n            let body_start = cap.get(0).map(|m| m.end()).unwrap_or(0);\n            let body = &code[body_start.saturating_sub(80)..body_start];\n            let names: Vec<&str> = params\n                .split(',')\n                .map(|p| p.trim().trim_start_matches(\"...\"))\n                .filter(|p| !p.is_empty())\n                .collect();\n            if !names.is_empty() && !names.iter().any(|n| body.contains(n)) {\n                return true;\n            }\n        }\n    }\n    if let Ok(re) = Regex::new(r#\"(?s)\\(([^)]*[^\\s)])\\)\\s*=>\\s*(?:\\d+|true|false|null|\"[^\"]*\"|'[^']*')\\b\"#) {\n        if let Some(cap) = re.captures(code) {\n            let params = cap.get(1).map(|m| m.as_str()).unwrap_or(\"\");\n            let names: Vec<&str> = params\n                .split(',')\n                .map(|p| p.trim().trim_start_matches(\"...\"))\n                .filter(|p| !p.is_empty())\n                .collect();\n            if !names.is_empty() {\n                return true; // arrow literal return can’t reference params\n                             // inline before =>\n            }\n        }\n    }\n    false\n}\n\n// Heuristic: approximate number of call-like tokens (identifier followed by\n// '(')\nfn count_call_like_tokens(s: &str) -> usize {\n    let mut c = 0usize;\n    let bytes = s.as_bytes();\n    let mut i = 0usize;\n    while i + 1 < bytes.len() {\n        let ch = bytes[i] as char;\n        if (ch.is_ascii_alphabetic() || ch == '_') {\n            let mut j = i + 1;\n            while j < bytes.len() {\n                let cj = bytes[j] as char;\n                if cj.is_ascii_alphanumeric() || cj == '_' {\n                    j += 1;\n                    continue;\n                }\n                break;\n            }\n            if j < bytes.len() && bytes[j] == b'(' {\n                // Cheap filters to avoid keywords/defs\n                let ident = &s[i..j].to_ascii_lowercase();\n                if ident != \"if\"\n                    && ident != \"for\"\n                    && ident != \"while\"\n                    && ident != \"switch\"\n                    && ident != \"return\"\n                    && ident != \"function\"\n                    && ident != \"def\"\n                    && ident != \"class\"\n                {\n                    c += 1;\n                }\n            }\n            i = j;\n            continue;\n        }\n        i += 1;\n    }\n    c\n}\n\n// Removed GrokSecurityClient - now using UniversalAIClient from ai_providers\n// module\n\nuse std::path::PathBuf;\n\n/// Validate path for security and ensure it's a directory\nfn validate_prompts_path(path: &PathBuf) -> Option<PathBuf> {\n    // Canonicalize handles path traversal, symlinks, and normalization\n    match std::fs::canonicalize(path) {\n        Ok(canonical) => {\n            if canonical.is_dir() {\n                Some(canonical)\n            } else {\n                None\n            }\n        }\n        Err(e) => {\n            tracing::warn!(error=%e, \"Cannot validate prompts path\");\n            None\n        }\n    }\n}\n\n/// Get the prompts directory path - always next to executable\nfn get_prompts_dir() -> PathBuf {\n    // Always look for prompts directory next to executable\n    let exe_path = match std::env::current_exe() {\n        Ok(path) => path,\n        Err(e) => {\n            tracing::error!(error=%e, \"Cannot determine executable path; falling back to ./prompts\");\n            return PathBuf::from(\"prompts\");\n        }\n    };\n\n    let parent = match exe_path.parent() {\n        Some(parent) => parent,\n        None => {\n            tracing::error!(\"Cannot get parent directory of executable; falling back to ./prompts\");\n            return PathBuf::from(\"prompts\");\n        }\n    };\n\n    // Production scenario: prompts directory next to executable\n    let prompts_path = parent.join(\"prompts\");\n\n    if let Some(validated) = validate_prompts_path(&prompts_path) {\n        tracing::info!(dir=?validated, \"Using prompts directory\");\n        return validated;\n    }\n\n    // Final fallback\n    tracing::warn!(\"Prompts directory not found next to executable; using current directory\");\n    PathBuf::from(\"prompts\")\n}\n\n/// Load prompt from file relative to prompts directory with security validation\nfn load_prompt(prompt_file: &str) -> Result<String> {\n    // Validate filename to prevent path traversal\n    let path = std::path::Path::new(prompt_file);\n\n    // Check for path traversal attempts\n    if prompt_file.contains(\"..\") || prompt_file.contains(\"/\") || prompt_file.contains(\"\\\\\") {\n        anyhow::bail!(\n            \"Invalid prompt filename - must be a simple filename without path separators: {}\",\n            prompt_file\n        );\n    }\n\n    // Additional validation: ensure it's just a filename\n    let components: Vec<_> = path.components().collect();\n    if components.len() != 1 || !matches!(components[0], std::path::Component::Normal(_)) {\n        anyhow::bail!(\n            \"Invalid prompt filename - must be a simple filename: {}\",\n            prompt_file\n        );\n    }\n\n    let prompt_path = get_prompts_dir().join(prompt_file);\n\n    // Final validation: ensure the resolved path is within the prompts directory\n    if let (Ok(canonical_prompt), Ok(canonical_dir)) = (\n        std::fs::canonicalize(&prompt_path),\n        std::fs::canonicalize(get_prompts_dir()),\n    ) {\n        if !canonical_prompt.starts_with(&canonical_dir) {\n            anyhow::bail!(\"Security error: prompt file path escapes the prompts directory\");\n        }\n    }\n\n    std::fs::read_to_string(&prompt_path)\n        .with_context(|| format!(\"Failed to read prompt file: {:?}\", prompt_path))\n}\n\n/// Read and summarize transcript from JSONL file with current task\n/// identification\nfn read_transcript_summary(path: &str, max_messages: usize, _max_chars: usize) -> Result<String> {\n    use std::io::BufRead;\n    use std::io::BufReader;\n\n    let file = File::open(path).context(\"Failed to open transcript file\")?;\n    let reader = BufReader::new(file);\n\n    let mut all_messages = Vec::new();\n\n    // Parse JSONL format - each line is a separate JSON object\n    for line in reader.lines() {\n        let line = line.context(\"Failed to read line from transcript\")?;\n        if line.trim().is_empty() {\n            continue;\n        }\n\n        if let Ok(entry) = serde_json::from_str::<serde_json::Value>(&line) {\n            // Extract message from the entry\n            if let Some(msg) = entry.get(\"message\") {\n                // Handle different message formats\n                if let Some(role) = msg.get(\"role\").and_then(|v| v.as_str()) {\n                    let content = if let Some(content_arr) = msg.get(\"content\").and_then(|v| v.as_array()) {\n                        // Handle content array (assistant messages)\n                        content_arr\n                            .iter()\n                            .filter_map(|c| {\n                                if let Some(text) = c.get(\"text\").and_then(|v| v.as_str()) {\n                                    Some(text.to_string())\n                                } else {\n                                    c.get(\"name\")\n                                        .and_then(|v| v.as_str())\n                                        .map(|tool_name| format!(\"[Tool: {}]\", tool_name))\n                                }\n                            })\n                            .collect::<Vec<_>>()\n                            .join(\" \")\n                    } else if let Some(text) = msg.get(\"content\").and_then(|v| v.as_str()) {\n                        // Handle simple string content (user messages)\n                        text.to_string()\n                    } else {\n                        String::new()\n                    };\n\n                    if !content.is_empty() {\n                        all_messages.push((role.to_string(), content));\n                    }\n                }\n            }\n        }\n    }\n\n    // Find the last user message to identify current task\n    let last_user_message = all_messages\n        .iter()\n        .rev()\n        .find(|(role, _)| role == \"user\")\n        .map(|(_, content)| content.clone());\n\n    // Take last N messages (max 20)\n    let max_msgs = max_messages.min(20);\n    let start = if all_messages.len() > max_msgs {\n        all_messages.len() - max_msgs\n    } else {\n        0\n    };\n\n    let mut result = String::new();\n    let mut char_count = 0;\n\n    // Add current task context at the beginning\n    if let Some(current_task) = &last_user_message {\n        let task_truncated = if current_task.chars().count() > 150 {\n            let truncated_chars: String = current_task.chars().take(147).collect();\n            format!(\"{}...\", truncated_chars)\n        } else {\n            current_task.clone()\n        };\n\n        let task_str = format!(\"CURRENT USER TASK: {}\\n\\nRECENT CONVERSATION:\\n\", task_truncated);\n        result.push_str(&task_str);\n        char_count += task_str.len();\n    }\n\n    for (role, content) in all_messages[start..].iter() {\n        // Truncate individual messages to 100 chars (UTF-8 safe)\n        let truncated = if content.chars().count() > 100 {\n            let truncated_chars: String = content.chars().take(97).collect();\n            format!(\"{}...\", truncated_chars)\n        } else {\n            content.clone()\n        };\n\n        // Mark the last user message as current task\n        let msg_str = if role == \"user\" && Some(content) == last_user_message.as_ref() {\n            format!(\"[{}] (CURRENT TASK): {}\\n\", role, truncated)\n        } else {\n            format!(\"[{}]: {}\\n\", role, truncated)\n        };\n\n        // Stop if we exceed 2000 chars\n        if char_count + msg_str.len() > 2000 {\n            result.push_str(\"...\\n\");\n            break;\n        }\n\n        result.push_str(&msg_str);\n        char_count += msg_str.len();\n    }\n\n    Ok(result)\n}\n\n// File structure checking function removed - AI handles all validation\n\n/// Build comprehensive error chain from an error\nfn build_error_chain(error: &dyn std::error::Error) -> Vec<String> {\n    const MAX_DEPTH: usize = 10;\n    const MAX_ERROR_LENGTH: usize = 500;\n\n    let mut error_chain = Vec::new();\n    let mut current_error = error;\n\n    // Add the main error\n    let main_error = current_error.to_string();\n    let truncated = if main_error.len() > MAX_ERROR_LENGTH {\n        format!(\"{}... (truncated)\", &main_error[..MAX_ERROR_LENGTH])\n    } else {\n        main_error\n    };\n    error_chain.push(truncated);\n\n    // Walk the error chain\n    let mut depth = 0;\n    while let Some(source) = current_error.source() {\n        let source_str = source.to_string();\n        let truncated = if source_str.len() > MAX_ERROR_LENGTH {\n            format!(\"{}... (truncated)\", &source_str[..MAX_ERROR_LENGTH])\n        } else {\n            source_str\n        };\n        error_chain.push(truncated);\n        current_error = source;\n        depth += 1;\n\n        if depth >= MAX_DEPTH {\n            error_chain.push(\"...error chain truncated (too deep)...\".to_string());\n            break;\n        }\n    }\n\n    error_chain\n}\n\n/// Format error chain into a comprehensive message\nfn format_error_message(error_chain: &[String]) -> String {\n    if error_chain.is_empty() {\n        return \"Unknown error occurred\".to_string();\n    }\n\n    if error_chain.len() == 1 {\n        error_chain[0].clone()\n    } else {\n        // Format as hierarchical error message\n        let mut message = error_chain[0].clone();\n        if error_chain.len() > 1 {\n            message.push_str(\"\\nDetails: \");\n            message.push_str(&error_chain[1..].join(\" <- \"));\n        }\n        message\n    }\n}\n\n/// Safely escape string for JSON output\nfn escape_json_string(s: &str) -> String {\n    let mut result = String::with_capacity(s.len() * 2);\n\n    for ch in s.chars() {\n        match ch {\n            '\"' => result.push_str(\"\\\\\\\"\"),\n            '\\\\' => result.push_str(\"\\\\\\\\\"),\n            '\\n' => result.push_str(\"\\\\n\"),\n            '\\r' => result.push_str(\"\\\\r\"),\n            '\\t' => result.push_str(\"\\\\t\"),\n            '\\u{0008}' => result.push_str(\"\\\\b\"),\n            '\\u{000C}' => result.push_str(\"\\\\f\"),\n            c if c.is_control() => {\n                // Escape other control characters as Unicode\n                result.push_str(&format!(\"\\\\u{:04x}\", c as u32));\n            }\n            c => result.push(c),\n        }\n    }\n\n    result\n}\n\n/// Format quality enforcement message for denied code\nfn format_quality_message(reason: &str) -> String {\n    // Replace literal \\n with actual newlines from AI response\n    let cleaned_reason = reason.replace(\"\\\\n\", \"\\n\");\n\n    format!(\n        \"РЕАЛИЗУЙТЕ КОД С КАЧЕСТВОМ, А НЕ ПРОСТО ЧТОБЫ ЗАВЕРШИТЬ ЗАДАЧУ\\n[плохой и поддельный код всегда будет заблокирован]\\n\\nвыявленные проблемы в ваших изменениях:\\n{}\\n\\nУЛУЧШИТЕ СВОЮ РАБОТУ — не убегайте от проблем, создавая минимальные упрощённые реализации\\n[попытки сделать это также будут заблокированы]\",\n        cleaned_reason\n    )\n}\n\n/// Output error response with proper fallback handling\nfn output_error_response(error: &anyhow::Error) {\n    // Build and log error chain\n    let error_chain = build_error_chain(&**error);\n\n    tracing::error!(\"PreToolUse validation error\");\n    tracing::debug!(?error, \"Detailed debug error\");\n    tracing::error!(%error, \"Display error\");\n    tracing::error!(depth = error_chain.len(), \"Error chain depth\");\n    for (i, err) in error_chain.iter().enumerate() {\n        tracing::error!(level = i, %err, \"Error chain element\");\n    }\n\n    // Format comprehensive error message\n    let error_message = format_error_message(&error_chain);\n    tracing::error!(message=%error_message, \"Final error message\");\n\n    // Create output structure\n    let output = PreToolUseOutput {\n        hook_specific_output: PreToolUseHookOutput {\n            hook_event_name: \"PreToolUse\".to_string(),\n            permission_decision: \"deny\".to_string(),\n            permission_decision_reason: Some(error_message.clone()),\n        },\n    };\n\n    // Try to serialize normally\n    match serde_json::to_string(&output) {\n        Ok(json) => {\n            println!(\"{}\", json);\n        }\n        Err(ser_err) => {\n            // Fallback with manual JSON construction\n            tracing::error!(error=%ser_err, \"Serialization failed for PreToolUse output\");\n            let escaped = escape_json_string(&error_message);\n            println!(\n                r#\"{{\"hook_specific_output\":{{\"hook_event_name\":\"PreToolUse\",\"permission_decision\":\"deny\",\"permission_decision_reason\":\"{}\"}}}}\"#,\n                escaped\n            );\n        }\n    }\n}\n\n/// Main PreToolUse hook execution\n#[tokio::main]\nasync fn main() -> Result<()> {\n    // Defensive: log any unexpected panic as a structured error\n    std::panic::set_hook(Box::new(|info| {\n        rust_validation_hooks::telemetry::init();\n        tracing::error!(panic=%info, \"panic in pretooluse\");\n    }));\n    // Initialize structured logging (stderr). Safe to call multiple times.\n    rust_validation_hooks::telemetry::init();\n    // Optional offline AST-only mode (no network): decide allow/deny from local\n    // AST/security heuristics\n    if dev_flag_enabled(\"PRETOOL_AST_ONLY\") {\n        // Read input from stdin\n        let mut input = String::new();\n        io::stdin()\n            .read_to_string(&mut input)\n            .context(\"Failed to read stdin\")?;\n        let hook_input: HookInput = serde_json::from_str(&input).context(\"Failed to parse hook input\")?;\n\n        // Extract file path and content to analyze\n        let file_path = extract_file_path(&hook_input.tool_input);\n        let language = file_path\n            .split('.')\n            .next_back()\n            .and_then(SupportedLanguage::from_extension);\n\n        let code: String = match hook_input.tool_name.as_str() {\n            \"Write\" => hook_input\n                .tool_input\n                .get(\"content\")\n                .and_then(|v| v.as_str())\n                .map(|s| s.to_string())\n                .or_else(|| std::fs::read_to_string(&file_path).ok())\n                .unwrap_or_default(),\n            \"Edit\" => hook_input\n                .tool_input\n                .get(\"new_string\")\n                .and_then(|v| v.as_str())\n                .map(|s| s.to_string())\n                .unwrap_or_else(|| std::fs::read_to_string(&file_path).unwrap_or_default()),\n            \"MultiEdit\" => {\n                if let Some(edits) = hook_input.tool_input.get(\"edits\").and_then(|v| v.as_array()) {\n                    let mut buf = String::new();\n                    for e in edits.iter().take(1000) {\n                        if let Some(ns) = e.get(\"new_string\").and_then(|v| v.as_str()) {\n                            buf.push_str(ns);\n                            buf.push('\\n');\n                        }\n                    }\n                    buf\n                } else {\n                    std::fs::read_to_string(&file_path).unwrap_or_default()\n                }\n            }\n            _ => String::new(),\n        };\n\n        // Default to allow if no code/language\n        if code.trim().is_empty() || language.is_none() {\n            let output = PreToolUseOutput {\n                hook_specific_output: PreToolUseHookOutput {\n                    hook_event_name: \"PreToolUse\".to_string(),\n                    permission_decision: \"allow\".to_string(),\n                    permission_decision_reason: None,\n                },\n            };\n            println!(\n                \"{}\",\n                serde_json::to_string(&output).context(\"Failed to serialize output\")?\n            );\n            return Ok(());\n        }\n\n        // Heuristic assessment for AST-only path\n        let heur = {\n            // Build a minimal HookInput clone to reuse helper\n            assess_change(&hook_input)\n        };\n\n        // Structural sanity: fast syntax check where available\n        if let Some(lang) = language {\n            if let Err(e) = MultiLanguageAnalyzer::analyze_with_tree_sitter_timeout(\n                &code,\n                lang,\n                std::time::Duration::from_millis(800),\n            ) {\n                // Treat parse/syntax errors as structural harm\n                let reason = format!(\"Structural integrity check failed: {e}\");\n                let output = PreToolUseOutput {\n                    hook_specific_output: PreToolUseHookOutput {\n                        hook_event_name: \"PreToolUse\".to_string(),\n                        permission_decision: \"deny\".to_string(),\n                        permission_decision_reason: Some(format_quality_message(&reason)),\n                    },\n                };\n                println!(\n                    \"{}\",\n                    serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                );\n                return Ok(());\n            }\n        }\n\n        // If WRITE is a no-op (old == new ignoring whitespace/comments), allow\n        if hook_input.tool_name == \"Write\" {\n            let (_p, old_opt, new_opt) = extract_old_new_contents(&hook_input);\n            if let (Some(o), Some(n)) = (old_opt, new_opt) {\n                if normalize_code_for_signal(&o) == normalize_code_for_signal(&n) {\n                    // If dangerous patterns present, do not allow silently\n                    let low = n.to_ascii_lowercase();\n                    let has_creds = low.contains(\"password\")\n                        || low.contains(\"secret\")\n                        || low.contains(\"api_key\")\n                        || low.contains(\"token\");\n                    let has_sql = (low.contains(\"select\") && low.contains(\"where\"))\n                        || (low.contains(\"insert\") && low.contains(\"values\"))\n                        || (low.contains(\"update\") && low.contains(\"set\"))\n                        || (low.contains(\"delete\") && low.contains(\"from\"));\n                    if !(has_creds || has_sql) {\n                        let output = PreToolUseOutput {\n                            hook_specific_output: PreToolUseHookOutput {\n                                hook_event_name: \"PreToolUse\".to_string(),\n                                permission_decision: \"allow\".to_string(),\n                                permission_decision_reason: None,\n                            },\n                        };\n                        println!(\n                            \"{}\",\n                            serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                        );\n                        return Ok(());\n                    }\n                }\n            }\n        }\n\n        if\n        /* do not block TODO/FIXME */\n        heur.has_empty_catch_or_except\n            || heur.has_silent_result_discard\n            || ((heur.is_return_constant_only || heur.is_print_or_log_only) && !heur.is_new_file_minimal)\n            || (detect_function_stub(language, &code) && hook_input.tool_name != \"Write\")\n        {\n            let reason = format!(\"Anti-cheating: {0}\", heur.summary);\n            let output = PreToolUseOutput {\n                hook_specific_output: PreToolUseHookOutput {\n                    hook_event_name: \"PreToolUse\".to_string(),\n                    permission_decision: \"deny\".to_string(),\n                    permission_decision_reason: Some(format_quality_message(&reason)),\n                },\n            };\n            println!(\n                \"{}\",\n                serde_json::to_string(&output).context(\"Failed to serialize output\")?\n            );\n            return Ok(());\n        }\n\n        // If EDIT is a no-op (old == new ignoring whitespace/comments), soft-deny\n        // (converted to deny)\n        if hook_input.tool_name == \"Edit\" {\n            let (_p, old_opt, new_opt) = extract_old_new_contents(&hook_input);\n            if let (Some(o), Some(n)) = (old_opt, new_opt) {\n                if normalize_code_for_signal(&o) == normalize_code_for_signal(&n) {\n                    let reason = \"No-op change (whitespace/comments only)\";\n                    let output = PreToolUseOutput {\n                        hook_specific_output: PreToolUseHookOutput {\n                            hook_event_name: \"PreToolUse\".to_string(),\n                            permission_decision: \"deny\".to_string(),\n                            permission_decision_reason: Some(format_quality_message(reason)),\n                        },\n                    };\n                    println!(\n                        \"{}\",\n                        serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                    );\n                    return Ok(());\n                }\n            }\n        }\n\n        // API contract weakening heuristic (deny in AST-only mode)\n        if hook_input.tool_name == \"Edit\" || hook_input.tool_name == \"MultiEdit\" {\n            let (path, old_opt, new_opt) = extract_old_new_contents(&hook_input);\n            if let (Some(old), Some(new)) = (old_opt, new_opt) {\n                let lang = path\n                    .split('.')\n                    .next_back()\n                    .and_then(SupportedLanguage::from_extension);\n                let reasons = contract_weakening_reasons(lang, &old, &new);\n                if !reasons.is_empty() {\n                    let reason = format!(\"API contract weakening detected:\\n{}\", reasons.join(\"\\n\"));\n                    let output = PreToolUseOutput {\n                        hook_specific_output: PreToolUseHookOutput {\n                            hook_event_name: \"PreToolUse\".to_string(),\n                            permission_decision: \"deny\".to_string(),\n                            permission_decision_reason: Some(format_quality_message(&reason)),\n                        },\n                    };\n                    println!(\n                        \"{}\",\n                        serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                    );\n                    return Ok(());\n                }\n            }\n        }\n\n        // Analyze with AST quality scorer\n        let scorer = analysis::ast::quality_scorer::AstQualityScorer::new();\n        // Avoid unwrap: re-check language presence defensively\n        let language = match language {\n            Some(l) => l,\n            None => {\n                let output = PreToolUseOutput {\n                    hook_specific_output: PreToolUseHookOutput {\n                        hook_event_name: \"PreToolUse\".to_string(),\n                        permission_decision: \"allow\".to_string(),\n                        permission_decision_reason: None,\n                    },\n                };\n                println!(\n                    \"{}\",\n                    serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                );\n                return Ok(());\n            }\n        };\n        let score =\n            scorer\n                .analyze(&code, language)\n                .unwrap_or_else(|_| analysis::ast::quality_scorer::QualityScore {\n                    total_score: 1000,\n                    functionality_score: 300,\n                    reliability_score: 200,\n                    maintainability_score: 200,\n                    performance_score: 150,\n                    security_score: 100,\n                    standards_score: 50,\n                    concrete_issues: vec![],\n                });\n\n        // Load runtime config (sensitivity, ignore globs, environment)\n        let cfg = config::load_config();\n\n        // Decide: deny on security signals based on sensitivity and context\n        use analysis::ast::quality_scorer::{IssueCategory, IssueSeverity};\n        let mut deny_reasons: Vec<String> = Vec::new();\n        for i in &score.concrete_issues {\n            // Do not block on unfinished work markers (TODO/FIXME/etc.) per policy\n            if matches!(i.category, IssueCategory::UnfinishedWork) {\n                continue;\n            }\n            // Skip ignored files\n            if config::should_ignore_path(&cfg, &file_path) {\n                continue;\n            }\n\n            // Determine effective severity threshold by sensitivity\n            let min_sev = match cfg.sensitivity {\n                config::Sensitivity::Low => IssueSeverity::Critical,\n                config::Sensitivity::Medium => IssueSeverity::Major,\n                config::Sensitivity::High => IssueSeverity::Minor,\n            };\n\n            // In test context, relax creds if allowlisted variables present in code\n            let is_test_ctx = config::is_test_context(&cfg, &file_path);\n            let allowlisted = config::code_contains_allowlisted_vars(&cfg, &code);\n\n            // Decide if issue should trigger deny\n            let mut triggers = false;\n            if i.severity as u8 <= min_sev as u8 {\n                // Severity ordering via discriminant: Critical(0) < Major(1) < Minor(2)\n                triggers = true;\n            }\n            // Always treat certain categories as critical triggers regardless of\n            // sensitivity\n            if matches!(\n                i.category,\n                IssueCategory::CommandInjection | IssueCategory::PathTraversal\n            ) {\n                triggers = true;\n            }\n\n            // Relax hardcoded creds in test context with allowlisted vars\n            if is_test_ctx && allowlisted && matches!(i.category, IssueCategory::HardcodedCredentials) {\n                triggers = false;\n            }\n\n            if triggers {\n                deny_reasons.push(format!(\"Line {}: {} [{}]\", i.line, i.message, i.rule_id));\n            }\n        }\n\n        let (permission_decision, permission_decision_reason) = if !deny_reasons.is_empty() {\n            (\n                \"deny\".to_string(),\n                Some(format_quality_message(&deny_reasons.join(\"\\n\"))),\n            )\n        } else {\n            (\"allow\".to_string(), None)\n        };\n\n        let output = PreToolUseOutput {\n            hook_specific_output: PreToolUseHookOutput {\n                hook_event_name: \"PreToolUse\".to_string(),\n                permission_decision,\n                permission_decision_reason,\n            },\n        };\n        println!(\n            \"{}\",\n            serde_json::to_string(&output).context(\"Failed to serialize output\")?\n        );\n        return Ok(());\n    }\n\n    // Load configuration (env/.env next to executable has priority)\n    let config = Config::from_env_graceful().context(\"Failed to load configuration\")?;\n\n    // Read input from stdin\n    let mut input = String::new();\n    io::stdin()\n        .read_to_string(&mut input)\n        .context(\"Failed to read stdin\")?;\n\n    // Parse hook input\n    let hook_input: HookInput = serde_json::from_str(&input).context(\"Failed to parse hook input\")?;\n\n    // Debug logging (to file) is disabled in release builds\n    if cfg!(debug_assertions) {\n        let log_file_path = std::env::temp_dir().join(\"pretooluse_debug.log\");\n        if let Ok(mut log_file) = std::fs::OpenOptions::new()\n            .create(true)\n            .append(true)\n            .open(&log_file_path)\n        {\n            use std::io::Write;\n            let timestamp = chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\");\n            writeln!(log_file, \"\\n=== PreToolUse Hook Debug [{}] ===\", timestamp).ok();\n            writeln!(log_file, \"Tool name: {}\", hook_input.tool_name).ok();\n            writeln!(log_file, \"Session ID: {:?}\", hook_input.session_id).ok();\n            writeln!(log_file, \"Transcript path: {:?}\", hook_input.transcript_path).ok();\n            writeln!(log_file, \"CWD: {:?}\", hook_input.cwd).ok();\n            writeln!(log_file, \"Hook event: {:?}\", hook_input.hook_event_name).ok();\n            writeln!(\n                log_file,\n                \"CLAUDE_PROJECT_DIR env: {:?}\",\n                std::env::var(\"CLAUDE_PROJECT_DIR\").ok()\n            )\n            .ok();\n\n            if let Some(transcript_path) = &hook_input.transcript_path {\n                writeln!(\n                    log_file,\n                    \"Attempting to read transcript from: {}\",\n                    transcript_path\n                )\n                .ok();\n                match read_transcript_summary(transcript_path, 15, 1500) {\n                    Ok(summary) => {\n                        writeln!(log_file, \"Transcript content (last 15 msgs, max 1500 chars):\").ok();\n                        writeln!(log_file, \"{}\", summary).ok();\n                    }\n                    Err(e) => {\n                        let _ = writeln!(log_file, \"Could not read transcript: {}\", e);\n                    }\n                }\n            }\n            writeln!(log_file, \"==============================\").ok();\n        }\n        tracing::info!(path=?log_file_path, \"PreToolUse hook: decision logged\");\n    }\n\n    // Extract content and file path\n    let content = extract_content_from_tool_input(&hook_input.tool_name, &hook_input.tool_input);\n    let file_path = extract_file_path(&hook_input.tool_input);\n\n    // Check project structure for Write operations (not Edit/MultiEdit)\n    if hook_input.tool_name == \"Write\" && !file_path.is_empty() {\n        // Get transcript context for checking user intent\n        let _transcript_context = if let Some(transcript_path) = &hook_input.transcript_path {\n            read_transcript_summary(transcript_path, 5, 500).ok()\n        } else {\n            None\n        };\n\n        // File structure checking removed - AI handles all validation now\n    }\n\n    // Test file validation removed - AI handles all validation now\n\n    // All operations now go through AI validation - no automatic allows\n\n    // All file validation now handled by AI - no automatic skipping based on file\n    // extensions\n\n    // If no API key for selected provider, fall back to offline AST-based decision\n    // path\n    if config\n        .get_api_key_for_provider(&config.pretool_provider)\n        .is_empty()\n    {\n        tracing::warn!(provider=%config.pretool_provider, \"No API key; falling back to AST-only validation\");\n        // Determine language from file extension\n        let language = file_path\n            .split('.')\n            .next_back()\n            .and_then(SupportedLanguage::from_extension);\n\n        // Default to allow if no code/language\n        if content.trim().is_empty() || language.is_none() {\n            let output = PreToolUseOutput {\n                hook_specific_output: PreToolUseHookOutput {\n                    hook_event_name: \"PreToolUse\".to_string(),\n                    permission_decision: \"allow\".to_string(),\n                    permission_decision_reason: None,\n                },\n            };\n            println!(\n                \"{}\",\n                serde_json::to_string(&output).context(\"Failed to serialize output\")?\n            );\n            return Ok(());\n        }\n\n        // Heuristic assessment\n        let heur = assess_change(&hook_input);\n\n        // Structural sanity: fast syntax check\n        if let Some(lang) = language {\n            if let Err(e) = MultiLanguageAnalyzer::analyze_with_tree_sitter_timeout(\n                &content,\n                lang,\n                std::time::Duration::from_millis(800),\n            ) {\n                let reason = format!(\"Structural integrity check failed: {e}\");\n                let output = PreToolUseOutput {\n                    hook_specific_output: PreToolUseHookOutput {\n                        hook_event_name: \"PreToolUse\".to_string(),\n                        permission_decision: \"deny\".to_string(),\n                        permission_decision_reason: Some(format_quality_message(&reason)),\n                    },\n                };\n                println!(\n                    \"{}\",\n                    serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                );\n                return Ok(());\n            }\n        }\n\n        // If WRITE is a no-op (old == new ignoring whitespace/comments), allow unless\n        // dangerous patterns\n        if hook_input.tool_name == \"Write\" {\n            let (_p, old_opt, new_opt) = extract_old_new_contents(&hook_input);\n            if let (Some(o), Some(n)) = (old_opt, new_opt) {\n                if normalize_code_for_signal(&o) == normalize_code_for_signal(&n) {\n                    let low = n.to_ascii_lowercase();\n                    let has_creds = low.contains(\"password\")\n                        || low.contains(\"secret\")\n                        || low.contains(\"api_key\")\n                        || low.contains(\"token\");\n                    let has_sql = (low.contains(\"select\") && low.contains(\"where\"))\n                        || (low.contains(\"insert\") && low.contains(\"values\"))\n                        || (low.contains(\"update\") && low.contains(\"set\"))\n                        || (low.contains(\"delete\") && low.contains(\"from\"));\n                    if !(has_creds || has_sql) {\n                        let output = PreToolUseOutput {\n                            hook_specific_output: PreToolUseHookOutput {\n                                hook_event_name: \"PreToolUse\".to_string(),\n                                permission_decision: \"allow\".to_string(),\n                                permission_decision_reason: None,\n                            },\n                        };\n                        println!(\n                            \"{}\",\n                            serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                        );\n                        return Ok(());\n                    }\n                }\n            }\n        }\n\n        // Block fake implementations\n        if\n        /* do not block TODO/FIXME */\n        heur.has_empty_catch_or_except\n            || heur.has_silent_result_discard\n            || ((heur.is_return_constant_only || heur.is_print_or_log_only) && !heur.is_new_file_minimal)\n            || (detect_function_stub(language, &content) && hook_input.tool_name != \"Write\")\n        {\n            let reason = format!(\"Anti-cheating: {0}\", heur.summary);\n            let output = PreToolUseOutput {\n                hook_specific_output: PreToolUseHookOutput {\n                    hook_event_name: \"PreToolUse\".to_string(),\n                    permission_decision: \"deny\".to_string(),\n                    permission_decision_reason: Some(format_quality_message(&reason)),\n                },\n            };\n            println!(\n                \"{}\",\n                serde_json::to_string(&output).context(\"Failed to serialize output\")?\n            );\n            return Ok(());\n        }\n\n        // No-op Edit → deny\n        if hook_input.tool_name == \"Edit\" {\n            let (_p, old_opt, new_opt) = extract_old_new_contents(&hook_input);\n            if let (Some(o), Some(n)) = (old_opt, new_opt) {\n                if normalize_code_for_signal(&o) == normalize_code_for_signal(&n) {\n                    let reason = \"No-op change (whitespace/comments only)\";\n                    let output = PreToolUseOutput {\n                        hook_specific_output: PreToolUseHookOutput {\n                            hook_event_name: \"PreToolUse\".to_string(),\n                            permission_decision: \"deny\".to_string(),\n                            permission_decision_reason: Some(format_quality_message(reason)),\n                        },\n                    };\n                    println!(\n                        \"{}\",\n                        serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                    );\n                    return Ok(());\n                }\n            }\n        }\n\n        // API contract weakening (deny)\n        if hook_input.tool_name == \"Edit\" || hook_input.tool_name == \"MultiEdit\" {\n            let (path, old_opt, new_opt) = extract_old_new_contents(&hook_input);\n            if let (Some(old), Some(new)) = (old_opt, new_opt) {\n                let lang = path\n                    .split('.')\n                    .next_back()\n                    .and_then(SupportedLanguage::from_extension);\n                let reasons = contract_weakening_reasons(lang, &old, &new);\n                if !reasons.is_empty() {\n                    let reason = format!(\"API contract weakening detected:\\n{}\", reasons.join(\"\\n\"));\n                    let output = PreToolUseOutput {\n                        hook_specific_output: PreToolUseHookOutput {\n                            hook_event_name: \"PreToolUse\".to_string(),\n                            permission_decision: \"deny\".to_string(),\n                            permission_decision_reason: Some(format_quality_message(&reason)),\n                        },\n                    };\n                    println!(\n                        \"{}\",\n                        serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                    );\n                    return Ok(());\n                }\n            }\n        }\n\n        // AST scoring\n        let scorer = analysis::ast::quality_scorer::AstQualityScorer::new();\n        let language = match language {\n            Some(l) => l,\n            None => {\n                let output = PreToolUseOutput {\n                    hook_specific_output: PreToolUseHookOutput {\n                        hook_event_name: \"PreToolUse\".to_string(),\n                        permission_decision: \"allow\".to_string(),\n                        permission_decision_reason: None,\n                    },\n                };\n                println!(\n                    \"{}\",\n                    serde_json::to_string(&output).context(\"Failed to serialize output\")?\n                );\n                return Ok(());\n            }\n        };\n        let score = scorer.analyze(&content, language).unwrap_or_else(|_| {\n            analysis::ast::quality_scorer::QualityScore {\n                total_score: 1000,\n                functionality_score: 300,\n                reliability_score: 200,\n                maintainability_score: 200,\n                performance_score: 150,\n                security_score: 100,\n                standards_score: 50,\n                concrete_issues: vec![],\n            }\n        });\n\n        // Policy evaluation\n        let cfg = config::load_config();\n        use analysis::ast::quality_scorer::{IssueCategory, IssueSeverity};\n        let mut deny_reasons: Vec<String> = Vec::new();\n        for i in &score.concrete_issues {\n            if matches!(i.category, IssueCategory::UnfinishedWork) {\n                continue;\n            }\n            if config::should_ignore_path(&cfg, &file_path) {\n                continue;\n            }\n            let min_sev = match cfg.sensitivity {\n                config::Sensitivity::Low => IssueSeverity::Critical,\n                config::Sensitivity::Medium => IssueSeverity::Major,\n                config::Sensitivity::High => IssueSeverity::Minor,\n            };\n            let is_test_ctx = config::is_test_context(&cfg, &file_path);\n            let allowlisted = config::code_contains_allowlisted_vars(&cfg, &content);\n            let mut triggers = i.severity as u8 <= min_sev as u8;\n            if matches!(\n                i.category,\n                IssueCategory::SqlInjection | IssueCategory::CommandInjection | IssueCategory::PathTraversal\n            ) {\n                triggers = true;\n            }\n            if is_test_ctx && allowlisted && matches!(i.category, IssueCategory::HardcodedCredentials) {\n                triggers = false;\n            }\n            if triggers {\n                deny_reasons.push(format!(\"Line {}: {} [{}]\", i.line, i.message, i.rule_id));\n            }\n        }\n        let (decision, reason) = if deny_reasons.is_empty() {\n            (\"allow\".to_string(), None)\n        } else {\n            (\n                \"deny\".to_string(),\n                Some(format_quality_message(&deny_reasons.join(\"\\n\"))),\n            )\n        };\n        let output = PreToolUseOutput {\n            hook_specific_output: PreToolUseHookOutput {\n                hook_event_name: \"PreToolUse\".to_string(),\n                permission_decision: decision,\n                permission_decision_reason: reason,\n            },\n        };\n        println!(\n            \"{}\",\n            serde_json::to_string(&output).context(\"Failed to serialize output\")?\n        );\n        return Ok(());\n    }\n\n    // Perform security validation with context\n    match perform_validation(&config, &content, &hook_input).await {\n        Ok(validation) => {\n            let (decision, reason) = match validation.decision.as_str() {\n                \"allow\" => (\"allow\".to_string(), None),\n                \"deny\" | \"ask\" => {\n                    // Note: Claude Code hooks only support \"allow\" and \"deny\" decisions\n                    // \"ask\" must be converted to \"deny\" with an informative message\n                    if validation.decision == \"ask\" {\n                        tracing::info!(\n                            \"'ask' decision converted to 'deny' (Claude Code only supports allow/deny)\"\n                        );\n                    }\n                    let formatted_reason = format_quality_message(&validation.reason);\n                    (\"deny\".to_string(), Some(formatted_reason))\n                }\n                unknown => {\n                    tracing::warn!(decision=%unknown, \"Unknown validation decision; defaulting to deny for safety\");\n                    let formatted_reason =\n                        format_quality_message(&format!(\"Unknown decision type: {unknown}\"));\n                    (\"deny\".to_string(), Some(formatted_reason))\n                }\n            };\n\n            let output = PreToolUseOutput {\n                hook_specific_output: PreToolUseHookOutput {\n                    hook_event_name: \"PreToolUse\".to_string(),\n                    permission_decision: decision,\n                    permission_decision_reason: reason,\n                },\n            };\n            println!(\n                \"{}\",\n                serde_json::to_string(&output).context(\"Failed to serialize output\")?\n            );\n        }\n        Err(e) => {\n            output_error_response(&e);\n        }\n    }\n\n    Ok(())\n}\n\n/// Format code changes as diff for better AI understanding\nfn format_code_as_diff(hook_input: &HookInput) -> String {\n    let mut diff = String::new();\n\n    // Extract file path\n    let file_path = extract_file_path(&hook_input.tool_input);\n\n    match hook_input.tool_name.as_str() {\n        \"Edit\" => {\n            // Extract old_string and new_string from tool_input\n            if let Some(old_string) = hook_input.tool_input.get(\"old_string\").and_then(|v| v.as_str()) {\n                if let Some(new_string) = hook_input.tool_input.get(\"new_string\").and_then(|v| v.as_str()) {\n                    // Try to read the current file content for context\n                    let file_content = std::fs::read_to_string(&file_path).ok();\n                    diff = format_edit_diff(\n                        &file_path,\n                        file_content.as_deref(),\n                        old_string,\n                        new_string,\n                        3, // 3 lines of context\n                    );\n                }\n            }\n        }\n        \"MultiEdit\" => {\n            // Extract edits array from tool_input\n            if let Some(edits_value) = hook_input.tool_input.get(\"edits\") {\n                if let Some(edits_array) = edits_value.as_array() {\n                    let mut edits = Vec::new();\n                    for edit in edits_array {\n                        if let (Some(old), Some(new)) = (\n                            edit.get(\"old_string\").and_then(|v| v.as_str()),\n                            edit.get(\"new_string\").and_then(|v| v.as_str()),\n                        ) {\n                            edits.push((old.to_string(), new.to_string()));\n                        }\n                    }\n\n                    // Try to read the current file content for context\n                    let file_content = std::fs::read_to_string(&file_path).ok();\n\n                    diff = format_multi_edit_diff(&file_path, file_content.as_deref(), &edits);\n                }\n            }\n        }\n        \"Write\" => {\n            // For Write operations, show as new file creation\n            if let Some(content) = hook_input.tool_input.get(\"content\").and_then(|v| v.as_str()) {\n                // Check if file exists\n                let old_content = std::fs::read_to_string(&file_path).ok();\n\n                diff = format_code_diff(\n                    &file_path,\n                    old_content.as_deref(),\n                    Some(content),\n                    3, // 3 lines of context\n                );\n            }\n        }\n        _ => {\n            // For other operations, just show the content if available\n            let content = extract_content_from_tool_input(&hook_input.tool_name, &hook_input.tool_input);\n            if !content.is_empty() {\n                diff = format!(\"Content:\\n{content}\");\n            }\n        }\n    }\n\n    diff\n}\n\n/// Perform security validation using Grok with context\nasync fn perform_validation(\n    config: &Config,\n    content: &str,\n    hook_input: &HookInput,\n) -> Result<SecurityValidation> {\n    // Load security prompt and anti-patterns\n    let mut prompt = load_prompt(\"edit_validation.txt\").context(\"Failed to load edit validation prompt\")?;\n\n    // Load anti-patterns for comprehensive validation\n    let anti_patterns = load_prompt(\"anti_patterns.txt\").unwrap_or_else(|_| String::new());\n    if !anti_patterns.is_empty() {\n        prompt = format!(\"{prompt}\\n\\nANTI-PATTERNS REFERENCE:\\n{anti_patterns}\");\n    }\n\n    // Load language preference with fallback to RUSSIAN\n    let language = load_prompt(\"language.txt\")\n        .unwrap_or_else(|_| \"RUSSIAN\".to_string())\n        .trim()\n        .to_string();\n\n    // Extract file path and add it to context\n    let file_path = extract_file_path(&hook_input.tool_input);\n    if !file_path.is_empty() {\n        prompt = format!(\"{prompt}\\n\\nFILE BEING MODIFIED: {file_path}\");\n    }\n\n    // Format the code changes as diff for better AI understanding\n    let diff_context = format_code_as_diff(hook_input);\n    if !diff_context.is_empty() {\n        prompt = format!(\"{prompt}\\n\\nCODE CHANGES (diff format):\\n{diff_context}\");\n    }\n\n    // Add heuristic assessment to guide the validator\n    let assessment = assess_change(hook_input);\n    prompt = format!(\"{prompt}\\n\\nHEURISTIC SUMMARY: {0}\", assessment.summary);\n\n    // Add context from transcript if available\n    if let Some(transcript_path) = &hook_input.transcript_path {\n        match read_transcript_summary(transcript_path, 10, 1000) {\n            Ok(summary) => {\n                prompt = format!(\"{prompt}\\n\\nCONTEXT - Recent chat history:\\n{summary}\");\n            }\n            Err(e) => {\n                tracing::warn!(error=%e, \"Could not read transcript\");\n            }\n        }\n    }\n\n    // Add project context from environment\n    if let Ok(project_dir) = std::env::var(\"CLAUDE_PROJECT_DIR\") {\n        prompt = format!(\"{prompt}\\n\\nPROJECT: {project_dir}\");\n    }\n\n    // Add project structure context\n    // Try multiple sources for working directory\n    let working_dir = if let Some(cwd) = &hook_input.cwd {\n        cwd.clone()\n    } else if let Ok(project_dir) = std::env::var(\"CLAUDE_PROJECT_DIR\") {\n        project_dir\n    } else if let Ok(current) = std::env::current_dir() {\n        current.to_string_lossy().to_string()\n    } else {\n        \".\".to_string()\n    };\n\n    // Scan project structure with limited scope for performance\n    let scan_config = ScanConfig {\n        max_files: 800, // Increased limit per user request\n        max_depth: 5,\n        include_hidden_files: false,\n        follow_symlinks: false,\n    };\n\n    match scan_project_structure(&working_dir, Some(scan_config)) {\n        Ok(structure) => {\n            let project_context = format_project_structure_for_ai(&structure, 1500);\n            prompt = format!(\"{prompt}\\n\\nPROJECT STRUCTURE:\\n{project_context}\");\n\n            // Add detailed project metrics\n            let total_loc: usize = structure\n                .files\n                .iter()\n                .filter(|f| f.is_code_file)\n                .map(|f| f.size_bytes as usize / 50) // Rough estimate: 50 bytes per line\n                .sum();\n\n            let metrics = format!(\n                \"\\n\\nPROJECT METRICS:\\n  Total files: {}\\n  Estimated LOC: {}\\n  Code files: {}\",\n                structure.total_files,\n                total_loc,\n                structure.files.iter().filter(|f| f.is_code_file).count()\n            );\n            prompt = format!(\"{prompt}{metrics}\");\n\n            tracing::info!(files=%structure.total_files, dirs=%structure.directories.len(), est_loc=%total_loc, \"Added project structure context\");\n        }\n        Err(e) => {\n            tracing::warn!(error=%e, \"Could not scan project structure\");\n        }\n    }\n\n    // Add dependencies analysis\n    let working_dir_path = std::path::Path::new(&working_dir);\n    match analyze_project_dependencies(working_dir_path).await {\n        Ok(dependencies) => {\n            let deps_summary = format!(\n                \"\\n\\nPROJECT DEPENDENCIES:\\nTotal: {} dependencies ({} dev, {} production)\",\n                dependencies.total_count,\n                dependencies.dev_dependencies_count,\n                dependencies.total_count - dependencies.dev_dependencies_count\n            );\n            prompt = format!(\"{prompt}{deps_summary}\");\n\n            // Add details by package manager\n            let mut deps_by_manager: std::collections::HashMap<_, Vec<_>> = std::collections::HashMap::new();\n            for dep in &dependencies.dependencies {\n                deps_by_manager\n                    .entry(dep.package_manager.clone())\n                    .or_default()\n                    .push(dep);\n            }\n\n            for (manager, deps) in deps_by_manager {\n                let manager_summary = format!(\"\\n{}: {} dependencies\", manager, deps.len());\n                prompt = format!(\"{prompt}{manager_summary}\");\n            }\n\n            tracing::info!(total=%dependencies.total_count, outdated=%dependencies.outdated_count, \"Added dependencies context\");\n        }\n        Err(e) => {\n            tracing::warn!(error=%e, \"Could not analyze dependencies\");\n        }\n    }\n\n    // Add AST analysis if we have file content\n    if !content.is_empty() && !file_path.is_empty() {\n        // Determine language from file extension\n        let extension = std::path::Path::new(&file_path)\n            .extension()\n            .and_then(|ext| ext.to_str())\n            .unwrap_or(\"\");\n\n        if let Some(language) = SupportedLanguage::from_extension(extension) {\n            tracing::info!(%language, \"Performing AST analysis\");\n            match MultiLanguageAnalyzer::analyze_with_tree_sitter(content, language) {\n                Ok(complexity_metrics) => {\n                    let ast_summary = format!(\"\\n\\nAST ANALYSIS:\\n  Cyclomatic Complexity: {}\\n  Cognitive Complexity: {}\\n  Nesting Depth: {}\\n  Functions: {}\\n  Lines: {}\",\n                        complexity_metrics.cyclomatic_complexity,\n                        complexity_metrics.cognitive_complexity,\n                        complexity_metrics.nesting_depth,\n                        complexity_metrics.function_count,\n                        complexity_metrics.line_count);\n                    prompt = format!(\"{prompt}{ast_summary}\");\n\n                    tracing::info!(cyclomatic=%complexity_metrics.cyclomatic_complexity, cognitive=%complexity_metrics.cognitive_complexity, \"AST analysis complete\");\n                }\n                Err(e) => {\n                    tracing::warn!(error=%e, \"AST analysis failed\");\n                }\n            }\n        }\n    }\n\n    // Add language instruction at the end\n    prompt = format!(\"{}\\n\\nIMPORTANT: Respond in {} language.\", prompt, language);\n\n    // Heuristic summary: API contract weakening (adds bias for safer decision)\n    if !file_path.is_empty() && (hook_input.tool_name == \"Edit\" || hook_input.tool_name == \"MultiEdit\") {\n        let (path, old_opt, new_opt) = extract_old_new_contents(hook_input);\n        if let (Some(old), Some(new)) = (old_opt, new_opt) {\n            let lang = path\n                .split('.')\n                .next_back()\n                .and_then(SupportedLanguage::from_extension);\n            let reasons = contract_weakening_reasons(lang, &old, &new);\n            if !reasons.is_empty() {\n                let hs = format!(\n                    \"\\n\\nHEURISTIC SUMMARY:\\nAPI contract weakening suspected:\\n- {}\\n\",\n                    reasons.join(\"\\n- \")\n                );\n                prompt.push_str(&hs);\n            }\n        }\n    }\n\n    // Early gate: contract weakening under high sensitivity ⇒ deny\n    if let Some(file_path) = hook_input.tool_input.get(\"file_path\").and_then(|v| v.as_str()) {\n        let ext = std::path::Path::new(file_path)\n            .extension()\n            .and_then(|e| e.to_str());\n        let lang = ext.and_then(SupportedLanguage::from_extension);\n        // Load policy config (sensitivity)\n        let policy_cfg = rust_validation_hooks::config::load_config();\n        if hook_input.tool_name == \"Edit\" || hook_input.tool_name == \"MultiEdit\" {\n            let (_p, old_opt, new_opt) = extract_old_new_contents(hook_input);\n            if let (Some(old), Some(new)) = (old_opt, new_opt) {\n                let reasons = contract_weakening_reasons(lang, &old, &new);\n                if !reasons.is_empty() {\n                    let code_new = if !content.is_empty() { content } else { &new };\n                    let low = code_new.to_ascii_lowercase();\n                    let has_creds = low.contains(\"password\")\n                        || low.contains(\"secret\")\n                        || low.contains(\"api_key\")\n                        || low.contains(\"token\");\n                    let has_sql = (low.contains(\"select\") && low.contains(\"where\"))\n                        || (low.contains(\"insert\") && low.contains(\"values\"))\n                        || (low.contains(\"update\") && low.contains(\"set\"))\n                        || (low.contains(\"delete\") && low.contains(\"from\"));\n                    let has_cmd = low.contains(\"child_process.exec\")\n                        || low.contains(\"subprocess.\")\n                        || low.contains(\"os.system(\");\n                    let sec_risk = has_creds || has_sql || has_cmd;\n                    use rust_validation_hooks::config::Sensitivity;\n                    let call_issues = find_contract_callsite_issues(lang, &old, code_new);\n                    let trigger = matches!(policy_cfg.sensitivity, Sensitivity::High)\n                        || (matches!(policy_cfg.sensitivity, Sensitivity::Medium)\n                            && (sec_risk || !call_issues.is_empty()));\n                    if trigger {\n                        let mut msg = String::new();\n                        if sec_risk {\n                            msg.push_str(\"Security-sensitive change combined with API weakening. \");\n                        }\n                        msg.push_str(\"Please preserve API contract (do not remove/rename parameters) or provide a migration strategy.\\n\");\n                        msg.push_str(\"Detected issues:\\n- \");\n                        msg.push_str(&reasons.join(\"\\n- \"));\n                        if !call_issues.is_empty() {\n                            msg.push_str(\"\\n- \");\n                            msg.push_str(&call_issues.join(\"\\n- \"));\n                        }\n                        return Ok(SecurityValidation {\n                            decision: \"deny\".to_string(),\n                            reason: msg,\n                            security_concerns: Some(vec![\"api_contract\".to_string()]),\n                            risk_level: if sec_risk {\n                                \"high\".to_string()\n                            } else {\n                                \"medium\".to_string()\n                            },\n                        });\n                    }\n                }\n            }\n        }\n    }\n\n    // Initialize universal AI client with configured provider\n    let client = UniversalAIClient::new(config.clone()).context(\"Failed to create AI client\")?;\n\n    // Validate security using configured pretool provider\n    client\n        .validate_security_pretool(content, &prompt)\n        .await\n        .context(\"Security validation failed\")\n}\n","structuredPatch":[{"oldStart":745,"oldLines":6,"newStart":745,"newLines":7,"lines":["             assess.is_whitespace_or_comments_only = true;","         }","     }","+    let combined_old = old_opt.clone().unwrap_or_default();","     let combined_new = new_opt.clone().unwrap_or_default();","     assess.is_return_constant_only = detect_return_constant(&combined_new);","     assess.is_print_or_log_only = detect_print_only(&combined_new);"]}],"userModified":false,"replaceAll":false}}