/// Multi-provider AI client implementation
use anyhow::{Context, Result};
use reqwest::Client;
use serde::{Serialize, Deserialize};
use serde_json;
use std::time::Duration;
use url::Url;

use crate::{Config, SecurityValidation, GrokCodeAnalysis};

/// Supported AI providers for validation
#[derive(Debug, Clone, Copy, PartialEq, Serialize, Deserialize)]
pub enum AIProvider {
    #[serde(rename = "openai")]
    OpenAI,
    #[serde(rename = "anthropic")]
    Anthropic,
    #[serde(rename = "google")]
    Google,
    #[serde(rename = "xai")]
    XAI,
}

impl std::fmt::Display for AIProvider {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            AIProvider::OpenAI => "openai",
            AIProvider::Anthropic => "anthropic",
            AIProvider::Google => "google",
            AIProvider::XAI => "xai",
        };
        write!(f, "{}", name)
    }
}

impl std::str::FromStr for AIProvider {
    type Err = anyhow::Error;
    
    fn from_str(s: &str) -> Result<Self> {
        match s.to_lowercase().as_str() {
            "openai" => Ok(AIProvider::OpenAI),
            "anthropic" => Ok(AIProvider::Anthropic),
            "google" => Ok(AIProvider::Google),
            "xai" => Ok(AIProvider::XAI),
            _ => Err(anyhow::anyhow!("Invalid provider: {}. Supported: openai, anthropic, google, xai", s)),
        }
    }
}

impl AIProvider {
    /// Get the default base URL for this provider
    pub fn default_base_url(&self) -> &'static str {
        match self {
            AIProvider::OpenAI => "https://api.openai.com/v1",
            AIProvider::Anthropic => "https://api.anthropic.com",
            AIProvider::Google => "https://generativelanguage.googleapis.com/v1",
            AIProvider::XAI => "https://api.x.ai/v1",
        }
    }
}

/// Universal AI client that supports multiple providers
pub struct UniversalAIClient {
    client: Client,
    config: Config,
}

impl UniversalAIClient {
    pub fn new(config: Config) -> Result<Self> {
        let client = Client::builder()
            .timeout(Duration::from_secs(config.request_timeout_secs))
            .connect_timeout(Duration::from_secs(config.connect_timeout_secs))
            .build()
            .context("Failed to create HTTP client")?;
            
        Ok(Self { client, config })
    }
    
    /// Validate security using the configured pretool provider
    pub async fn validate_security_pretool(
        &self,
        code: &str,
        prompt: &str,
    ) -> Result<SecurityValidation> {
        match self.config.pretool_provider {
            AIProvider::OpenAI => {
                // Check if it's GPT-5 (uses different API)
                if self.config.pretool_model.starts_with("gpt-5") {
                    self.validate_with_gpt5(code, prompt).await
                } else {
                    self.validate_with_openai(code, prompt).await
                }
            }
            AIProvider::Anthropic => self.validate_with_anthropic(code, prompt).await,
            AIProvider::Google => self.validate_with_google(code, prompt).await,
            AIProvider::XAI => self.validate_with_xai(code, prompt).await,
        }
    }
    
    /// Analyze code using the configured posttool provider
    pub async fn analyze_code_posttool(
        &self,
        code: &str,
        prompt: &str,
    ) -> Result<GrokCodeAnalysis> {
        match self.config.posttool_provider {
            AIProvider::OpenAI => {
                // Check if it's GPT-5 (uses different API)
                if self.config.posttool_model.starts_with("gpt-5") {
                    self.analyze_with_gpt5(code, prompt).await
                } else {
                    self.analyze_with_openai(code, prompt).await
                }
            }
            AIProvider::Anthropic => self.analyze_with_anthropic(code, prompt).await,
            AIProvider::Google => self.analyze_with_google(code, prompt).await,
            AIProvider::XAI => self.analyze_with_xai(code, prompt).await,
        }
    }
    
    /// GPT-5 specific implementation (uses Responses API)
    async fn validate_with_gpt5(&self, code: &str, prompt: &str) -> Result<SecurityValidation> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::OpenAI);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::OpenAI);
        
        // GPT-5 uses the new Responses API format
        let request_body = serde_json::json!({
            "model": self.config.pretool_model,
            "input": [
                {
                    "role": "system",
                    "content": [
                        {
                            "type": "input_text",
                            "text": prompt
                        }
                    ]
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_text",
                            "text": format!("Analyze this code for security risks:\n\n{}", code)
                        }
                    ]
                }
            ],
            "text": {
                "format": {
                    "type": "json_schema",
                    "name": "SecurityValidation",
                    "schema": self.get_security_validation_schema()
                }
            },
            "max_output_tokens": 1024,
            "reasoning": {
                "effort": "low"
            },
            "store": false
        });
        
        let response = self.client
            .post(format!("{}/responses", base_url))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to GPT-5")?;
            
        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("GPT-5 API error: {}", error_text));
        }
        
        #[derive(Deserialize)]
        struct Gpt5Response {
            output: Vec<serde_json::Value>,
            output_text: Option<String>,
        }
        
        let gpt5_response: Gpt5Response = response.json().await
            .context("Failed to parse GPT-5 response")?;
        
        // Try output_text first, then extract from output array    
        let json_text = if let Some(text) = gpt5_response.output_text {
            text
        } else {
            // Extract text from output array
            Self::extract_text_from_output_array(&gpt5_response.output)
        };
            
        let validation: SecurityValidation = serde_json::from_str(&json_text)
            .context("Failed to parse security validation from GPT-5")?;
            
        Ok(validation)
    }
    
    /// Standard OpenAI implementation (GPT-4, GPT-3.5, etc.)
    async fn validate_with_openai(&self, code: &str, prompt: &str) -> Result<SecurityValidation> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::OpenAI);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::OpenAI);
        
        let request_body = serde_json::json!({
            "model": self.config.pretool_model,
            "messages": [
                {
                    "role": "system",
                    "content": prompt
                },
                {
                    "role": "user",
                    "content": format!("Analyze this code for security risks:\n\n{}", code)
                }
            ],
            "response_format": {
                "type": "json_schema",
                "json_schema": {
                    "name": "SecurityValidation",
                    "schema": self.get_security_validation_schema(),
                    "strict": true
                }
            },
            "max_tokens": 1024,
            "temperature": self.config.temperature
        });
        
        let response = self.client
            .post(format!("{}/chat/completions", base_url))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to OpenAI")?;
            
        self.parse_openai_response(response).await
    }
    
    /// Anthropic (Claude) implementation
    async fn validate_with_anthropic(&self, code: &str, prompt: &str) -> Result<SecurityValidation> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::Anthropic);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::Anthropic);
        
        let request_body = serde_json::json!({
            "model": self.config.pretool_model,
            "messages": [
                {
                    "role": "user",
                    "content": format!("{}\n\nAnalyze this code for security risks:\n\n{}", prompt, code)
                }
            ],
            "max_tokens": 1024,
            "temperature": self.config.temperature,
            "system": prompt
        });
        
        let response = self.client
            .post(format!("{}/v1/messages", base_url))
            .header("x-api-key", api_key)
            .header("anthropic-version", "2023-06-01")
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to Anthropic")?;
            
        self.parse_anthropic_response(response).await
    }
    
    /// Google (Gemini) implementation
    async fn validate_with_google(&self, code: &str, prompt: &str) -> Result<SecurityValidation> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::Google);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::Google);
        
        let request_body = serde_json::json!({
            "contents": [
                {
                    "parts": [
                        {
                            "text": format!("{}\n\nAnalyze this code for security risks:\n\n{}", prompt, code)
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": self.config.temperature,
                "maxOutputTokens": 1024,
                "responseMimeType": "application/json",
                "responseSchema": self.get_security_validation_schema()
            }
        });
        
        let model_name = &self.config.pretool_model;
        let response = self.client
            .post(format!("{}/models/{}:generateContent?key={}", base_url, model_name, api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to Google")?;
            
        self.parse_google_response(response).await
    }
    
    /// xAI (Grok) implementation
    async fn validate_with_xai(&self, code: &str, prompt: &str) -> Result<SecurityValidation> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::XAI);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::XAI);
        
        let request_body = serde_json::json!({
            "model": self.config.pretool_model,
            "messages": [
                {
                    "role": "system",
                    "content": prompt
                },
                {
                    "role": "user",
                    "content": format!("Analyze this code for security risks:\n\n{}", code)
                }
            ],
            "response_format": {
                "type": "json_schema",
                "json_schema": {
                    "name": "SecurityValidation",
                    "schema": self.get_security_validation_schema()
                }
            },
            "max_tokens": 1024,
            "temperature": self.config.temperature,
            "stream": false
        });
        
        let response = self.client
            .post(format!("{}/chat/completions", base_url))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to xAI")?;
            
        self.parse_openai_response(response).await  // xAI uses OpenAI-compatible format
    }
    
    /// Get the JSON schema for security validation
    fn get_security_validation_schema(&self) -> serde_json::Value {
        serde_json::json!({
            "type": "object",
            "required": ["decision", "reason", "risk_level", "security_concerns"],
            "additionalProperties": false,
            "properties": {
                "decision": {
                    "type": "string",
                    "enum": ["allow", "ask", "deny"]
                },
                "reason": {
                    "type": "string",
                    "maxLength": 500
                },
                "security_concerns": {
                    "type": ["array", "null"],
                    "maxItems": 5,
                    "items": {
                        "type": "string",
                        "maxLength": 200
                    }
                },
                "risk_level": {
                    "type": "string",
                    "enum": ["low", "medium", "high", "critical"]
                }
            }
        })
    }
    
    /// Get the JSON schema for code analysis
    fn get_code_analysis_schema(&self) -> serde_json::Value {
        serde_json::json!({
            "type": "object",
            "required": ["summary", "overall_quality", "issues", "suggestions"],
            "additionalProperties": false,
            "properties": {
                "summary": {
                    "type": "string",
                    "maxLength": 500
                },
                "overall_quality": {
                    "type": "string",
                    "enum": ["excellent", "good", "needs_improvement", "poor"]
                },
                "issues": {
                    "type": "array",
                    "maxItems": 20,
                    "items": {
                        "type": "object",
                        "required": ["severity", "category", "message"],
                        "properties": {
                            "severity": {
                                "type": "string",
                                "enum": ["info", "minor", "major", "critical", "blocker"]
                            },
                            "category": {
                                "type": "string",
                                "enum": ["intent", "correctness", "security", "robustness", "maintainability", "performance", "tests", "lint"]
                            },
                            "message": {
                                "type": "string",
                                "maxLength": 300
                            },
                            "line": {"type": "integer"},
                            "impact": {"type": "integer", "minimum": 1, "maximum": 3},
                            "fix_cost": {"type": "integer", "minimum": 1, "maximum": 3},
                            "confidence": {"type": "number", "minimum": 0.5, "maximum": 1.0},
                            "fix_suggestion": {"type": "string", "maxLength": 200}
                        }
                    }
                },
                "suggestions": {
                    "type": "array",
                    "maxItems": 10,
                    "items": {
                        "type": "object",
                        "required": ["category", "description", "priority"],
                        "properties": {
                            "category": {"type": "string"},
                            "description": {"type": "string", "maxLength": 300},
                            "priority": {
                                "type": "string",
                                "enum": ["high", "medium", "low"]
                            },
                            "priority_score": {"type": "number", "minimum": 0, "maximum": 100},
                            "code_example": {"type": "string"}
                        }
                    }
                },
                "metrics": {
                    "type": "object",
                    "properties": {
                        "complexity": {
                            "type": "string",
                            "enum": ["low", "medium", "high"]
                        },
                        "readability": {
                            "type": "string",
                            "enum": ["excellent", "good", "fair", "poor"]
                        },
                        "test_coverage": {
                            "type": "string",
                            "enum": ["none", "partial", "good", "excellent"]
                        }
                    }
                }
            }
        })
    }
    
    /// Parse OpenAI-compatible response
    async fn parse_openai_response(&self, response: reqwest::Response) -> Result<SecurityValidation> {
        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("API error: {}", error_text));
        }
        
        #[derive(Deserialize)]
        struct OpenAIResponse {
            choices: Vec<Choice>,
        }
        
        #[derive(Deserialize)]
        struct Choice {
            message: Message,
        }
        
        #[derive(Deserialize)]
        struct Message {
            content: String,
        }
        
        let api_response: OpenAIResponse = response.json().await
            .context("Failed to parse API response")?;
            
        let content = api_response.choices.first()
            .ok_or_else(|| anyhow::anyhow!("No choices in response"))?
            .message.content.clone();
            
        let validation: SecurityValidation = serde_json::from_str(&content)
            .context("Failed to parse security validation")?;
            
        Ok(validation)
    }
    
    /// Parse Anthropic response
    async fn parse_anthropic_response(&self, response: reqwest::Response) -> Result<SecurityValidation> {
        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("Anthropic API error: {}", error_text));
        }
        
        #[derive(Deserialize)]
        struct AnthropicResponse {
            content: Vec<Content>,
        }
        
        #[derive(Deserialize)]
        struct Content {
            text: String,
        }
        
        let api_response: AnthropicResponse = response.json().await
            .context("Failed to parse Anthropic response")?;
            
        let text = api_response.content.first()
            .ok_or_else(|| anyhow::anyhow!("No content in Anthropic response"))?
            .text.clone();
            
        let validation: SecurityValidation = serde_json::from_str(&text)
            .context("Failed to parse security validation from Anthropic")?;
            
        Ok(validation)
    }
    
    /// Parse Google response
    async fn parse_google_response(&self, response: reqwest::Response) -> Result<SecurityValidation> {
        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("Google API error: {}", error_text));
        }
        
        #[derive(Deserialize)]
        struct GoogleResponse {
            candidates: Vec<Candidate>,
        }
        
        #[derive(Deserialize)]
        struct Candidate {
            content: ContentPart,
        }
        
        #[derive(Deserialize)]
        struct ContentPart {
            parts: Vec<Part>,
        }
        
        #[derive(Deserialize)]
        struct Part {
            text: String,
        }
        
        let api_response: GoogleResponse = response.json().await
            .context("Failed to parse Google response")?;
            
        let text = api_response.candidates.first()
            .and_then(|c| c.content.parts.first())
            .ok_or_else(|| anyhow::anyhow!("No content in Google response"))?
            .text.clone();
            
        let validation: SecurityValidation = serde_json::from_str(&text)
            .context("Failed to parse security validation from Google")?;
            
        Ok(validation)
    }
    
    // Code analysis methods for PostToolUse hook
    
    /// Analyze code with GPT-5 (uses Responses API)
    async fn analyze_with_gpt5(&self, code: &str, prompt: &str) -> Result<GrokCodeAnalysis> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::OpenAI);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::OpenAI);
        
        let request_body = serde_json::json!({
            "model": self.config.posttool_model,
            "input": [
                {
                    "role": "system",
                    "content": [
                        {
                            "type": "input_text",
                            "text": prompt
                        }
                    ]
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_text",
                            "text": format!("Analyze this code and provide detailed review:\n\n{}", code)
                        }
                    ]
                }
            ],
            "text": {
                "format": {
                    "type": "json_schema",
                    "name": "GrokCodeAnalysis",
                    "schema": self.get_code_analysis_schema()
                }
            },
            "max_output_tokens": 2048,
            "reasoning": {
                "effort": "high"
            },
            "store": false
        });
        
        let response = self.client
            .post(format!("{}/responses", base_url))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to GPT-5")?;
            
        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("GPT-5 API error: {}", error_text));
        }
        
        #[derive(Deserialize)]
        struct Gpt5Response {
            output_text: String,
        }
        
        let gpt5_response: Gpt5Response = response.json().await
            .context("Failed to parse GPT-5 response")?;
            
        let analysis: GrokCodeAnalysis = serde_json::from_str(&gpt5_response.output_text)
            .context("Failed to parse code analysis from GPT-5")?;
            
        Ok(analysis)
    }
    
    /// Analyze code with standard OpenAI models
    async fn analyze_with_openai(&self, code: &str, prompt: &str) -> Result<GrokCodeAnalysis> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::OpenAI);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::OpenAI);
        
        let request_body = serde_json::json!({
            "model": self.config.posttool_model,
            "messages": [
                {
                    "role": "system",
                    "content": prompt
                },
                {
                    "role": "user",
                    "content": format!("Analyze this code and provide detailed review:\n\n{}", code)
                }
            ],
            "response_format": {
                "type": "json_schema",
                "json_schema": {
                    "name": "GrokCodeAnalysis",
                    "schema": self.get_code_analysis_schema(),
                    "strict": true
                }
            },
            "max_tokens": 2048,
            "temperature": self.config.temperature
        });
        
        let response = self.client
            .post(format!("{}/chat/completions", base_url))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to OpenAI")?;
            
        self.parse_openai_analysis_response(response).await
    }
    
    /// Analyze code with Anthropic Claude
    async fn analyze_with_anthropic(&self, code: &str, prompt: &str) -> Result<GrokCodeAnalysis> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::Anthropic);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::Anthropic);
        
        let request_body = serde_json::json!({
            "model": self.config.posttool_model,
            "messages": [
                {
                    "role": "user",
                    "content": format!("{}\\n\\nAnalyze this code and provide detailed review:\\n\\n{}", prompt, code)
                }
            ],
            "max_tokens": 2048,
            "temperature": self.config.temperature,
            "system": prompt
        });
        
        let response = self.client
            .post(format!("{}/v1/messages", base_url))
            .header("x-api-key", api_key)
            .header("anthropic-version", "2023-06-01")
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to Anthropic")?;
            
        self.parse_anthropic_analysis_response(response).await
    }
    
    /// Analyze code with Google Gemini
    async fn analyze_with_google(&self, code: &str, prompt: &str) -> Result<GrokCodeAnalysis> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::Google);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::Google);
        
        let request_body = serde_json::json!({
            "contents": [
                {
                    "parts": [
                        {
                            "text": format!("{}\\n\\nAnalyze this code and provide detailed review:\\n\\n{}", prompt, code)
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": self.config.temperature,
                "maxOutputTokens": 2048,
                "responseMimeType": "application/json",
                "responseSchema": self.get_code_analysis_schema()
            }
        });
        
        let model_name = &self.config.posttool_model;
        let response = self.client
            .post(format!("{}/models/{}:generateContent?key={}", base_url, model_name, api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to Google")?;
            
        self.parse_google_analysis_response(response).await
    }
    
    /// Analyze code with xAI Grok
    async fn analyze_with_xai(&self, code: &str, prompt: &str) -> Result<GrokCodeAnalysis> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::XAI);
        let base_url = self.config.get_base_url_for_provider(&AIProvider::XAI);
        
        let request_body = serde_json::json!({
            "model": self.config.posttool_model,
            "messages": [
                {
                    "role": "system",
                    "content": prompt
                },
                {
                    "role": "user",
                    "content": format!("Analyze this code and provide detailed review:\\n\\n{}", code)
                }
            ],
            "response_format": {
                "type": "json_schema",
                "json_schema": {
                    "name": "GrokCodeAnalysis",
                    "schema": self.get_code_analysis_schema()
                }
            },
            "max_tokens": 2048,
            "temperature": self.config.temperature,
            "stream": false
        });
        
        let response = self.client
            .post(format!("{}/chat/completions", base_url))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .context("Failed to send request to xAI")?;
            
        self.parse_openai_analysis_response(response).await  // xAI uses OpenAI-compatible format
    }
    
    // Helper methods to parse analysis responses
    
    async fn parse_openai_analysis_response(&self, response: reqwest::Response) -> Result<GrokCodeAnalysis> {
        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("API error: {}", error_text));
        }
        
        #[derive(Deserialize)]
        struct OpenAIResponse {
            choices: Vec<Choice>,
        }
        
        #[derive(Deserialize)]
        struct Choice {
            message: Message,
        }
        
        #[derive(Deserialize)]
        struct Message {
            content: String,
        }
        
        let api_response: OpenAIResponse = response.json().await
            .context("Failed to parse API response")?;
            
        let content = api_response.choices.first()
            .ok_or_else(|| anyhow::anyhow!("No choices in response"))?
            .message.content.clone();
            
        let analysis: GrokCodeAnalysis = serde_json::from_str(&content)
            .context("Failed to parse code analysis")?;
            
        Ok(analysis)
    }
    
    async fn parse_anthropic_analysis_response(&self, response: reqwest::Response) -> Result<GrokCodeAnalysis> {
        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("Anthropic API error: {}", error_text));
        }
        
        #[derive(Deserialize)]
        struct AnthropicResponse {
            content: Vec<Content>,
        }
        
        #[derive(Deserialize)]
        struct Content {
            text: String,
        }
        
        let api_response: AnthropicResponse = response.json().await
            .context("Failed to parse Anthropic response")?;
            
        let text = api_response.content.first()
            .ok_or_else(|| anyhow::anyhow!("No content in Anthropic response"))?
            .text.clone();
            
        let analysis: GrokCodeAnalysis = serde_json::from_str(&text)
            .context("Failed to parse code analysis from Anthropic")?;
            
        Ok(analysis)
    }
    
    async fn parse_google_analysis_response(&self, response: reqwest::Response) -> Result<GrokCodeAnalysis> {
        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("Google API error: {}", error_text));
        }
        
        #[derive(Deserialize)]
        struct GoogleResponse {
            candidates: Vec<Candidate>,
        }
        
        #[derive(Deserialize)]
        struct Candidate {
            content: ContentPart,
        }
        
        #[derive(Deserialize)]
        struct ContentPart {
            parts: Vec<Part>,
        }
        
        #[derive(Deserialize)]
        struct Part {
            text: String,
        }
        
        let api_response: GoogleResponse = response.json().await
            .context("Failed to parse Google response")?;
            
        let text = api_response.candidates.first()
            .and_then(|c| c.content.parts.first())
            .ok_or_else(|| anyhow::anyhow!("No content in Google response"))?
            .text.clone();
            
        let analysis: GrokCodeAnalysis = serde_json::from_str(&text)
            .context("Failed to parse code analysis from Google")?;
            
        Ok(analysis)
    }
    
    /// Extract text content from GPT-5 output array
    fn extract_text_from_output_array(output: &[serde_json::Value]) -> String {
        for output_item in output.iter() {
            // Handle GPT-5 message structure: output_item.content[].text
            if let Some(content_array) = output_item.get("content").and_then(|v| v.as_array()) {
                for content_entry in content_array {
                    if let Some(text_content) = content_entry.get("text").and_then(|v| v.as_str()) {
                        let trimmed_text = text_content.trim();
                        if !trimmed_text.is_empty() {
                            return trimmed_text.to_string();
                        }
                    }
                }
            } else if let Some(direct_content) = output_item.get("content").and_then(|v| v.as_str()) {
                // Fallback for direct string content
                let trimmed_content = direct_content.trim();
                if !trimmed_content.is_empty() {
                    return trimmed_content.to_string();
                }
            }
        }
        String::new() // Return empty string if no content found
    }

    /// Optimize memory using GPT-5 with Responses API
    pub async fn optimize_memory_gpt5(
        &self,
        context: &str,
        prompt: &str,
        model: &str,
    ) -> Result<serde_json::Value> {
        let api_key = self.config.get_api_key_for_provider(&AIProvider::OpenAI);
        if api_key.is_empty() {
            return Err(anyhow::anyhow!("OpenAI API key not configured"));
        }
        eprintln!("GPT-5 Debug: Using API key ending with: ...{}", &api_key[api_key.len()-10..]);
        
        let base_url = self.config.get_base_url_for_provider(&AIProvider::OpenAI);
        
        // GPT-5 uses the new Responses API format - simple input string works better
        let request_body = serde_json::json!({
            "model": model,
            "input": format!("{}\n\n{}", prompt, context),
            "text": {
                "format": {
                    "type": "json_schema",
                    "name": "MemoryOptimization",
                    "schema": self.get_memory_optimization_schema()
                }
            },
            "max_output_tokens": 15000,
            "reasoning": {
                "effort": "medium"
            },
            "store": false
        });
        
        // Debug logging for GPT-5 troubleshooting
        eprintln!("GPT-5 Debug: Model = {}", model);
        
        // Implement retry logic for transient failures
        let mut retries = 3;
        let mut last_error = None;
        
        while retries > 0 {
            // Construct proper URL - build directly since base_url already includes /v1
            let responses_url_string = format!("{}/responses", base_url.trim_end_matches('/'));
            let responses_url = Url::parse(&responses_url_string)
                .with_context(|| format!("Failed to parse responses URL: {}", responses_url_string))?;
            
            eprintln!("GPT-5 Debug: Requesting URL = {}", responses_url);
            
            let response = self.client
                .post(responses_url)
                .header("Authorization", format!("Bearer {}", api_key))
                .header("Content-Type", "application/json")
                .header("User-Agent", "rust-validation-hooks/0.1.0")
                .json(&request_body)
                .send()
                .await;
                
            match response {
                Ok(resp) => {
                    if resp.status().is_success() {
                        #[derive(Deserialize)]
                        struct Gpt5Response {
                            output_text: Option<String>,
                            output: Option<Vec<serde_json::Value>>,
                        }
                        
                        match resp.json::<Gpt5Response>().await {
                            Ok(gpt5_response) => {
                                eprintln!("GPT-5 response received, extracting content...");
                                
                                // Try output_text first, then extract from output array
                                let text_content = if let Some(output_text) = gpt5_response.output_text {
                                    eprintln!("Using output_text field");
                                    output_text
                                } else if let Some(output) = gpt5_response.output {
                                    eprintln!("Extracting from output array with {} items", output.len());
                                    eprintln!("Full output array: {}", serde_json::to_string_pretty(&output).unwrap_or_default());
                                    Self::extract_text_from_output_array(&output)
                                } else {
                                    return Err(anyhow::anyhow!("No output content found in response"));
                                };
                                
                                // Check if content is empty
                                if text_content.trim().is_empty() {
                                    last_error = Some(anyhow::anyhow!("Response content is empty"));
                                    eprintln!("GPT-5 response content is empty");
                                } else {
                                    eprintln!("Parsing content of length: {}", text_content.len());
                                    match serde_json::from_str::<serde_json::Value>(&text_content) {
                                        Ok(optimization) => return Ok(optimization),
                                        Err(e) => {
                                            eprintln!("Failed to parse JSON response: {}", e);
                                            eprintln!("Response content: {}", text_content);
                                            last_error = Some(anyhow::anyhow!("Failed to parse optimization: {}", e));
                                        }
                                    }
                                }
                            }
                            Err(e) => {
                                last_error = Some(anyhow::anyhow!("Failed to parse response: {}", e));
                            }
                        }
                    } else {
                        let status = resp.status();
                        // Don't log the full error text as it might contain sensitive info
                        last_error = Some(anyhow::anyhow!("API request failed with status {}", status));
                        eprintln!("GPT-5 API error (attempt {}): Status {}", 4 - retries, status);
                    }
                }
                Err(e) => {
                    last_error = Some(anyhow::anyhow!("Network error: {}", e));
                    eprintln!("Network error (attempt {}): {}", 4 - retries, e);
                }
            }
            
            retries -= 1;
            if retries > 0 {
                // Wait before retrying (exponential backoff)
                tokio::time::sleep(std::time::Duration::from_secs(2_u64.pow(3 - retries as u32))).await;
            }
        }
        
        Err(last_error.unwrap_or_else(|| anyhow::anyhow!("Failed to call GPT-5 after 3 attempts")))
    }
    
    /// Get the JSON schema for memory optimization
    fn get_memory_optimization_schema(&self) -> serde_json::Value {
        serde_json::json!({
            "type": "object",
            "required": ["optimized_memories", "total_tokens", "reduction_ratio", "key_insights"],
            "additionalProperties": false,
            "properties": {
                "optimized_memories": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["timestamp", "category", "content", "relevance_score"],
                        "additionalProperties": false,
                        "properties": {
                            "timestamp": {
                                "type": "string"
                            },
                            "category": {
                                "type": "string",
                                "enum": ["TASKS", "SOLUTIONS", "ERRORS", "DECISIONS", "CONTEXT", "TOOLS", "INSIGHTS"]
                            },
                            "content": {
                                "type": "string"
                            },
                            "relevance_score": {
                                "type": "number",
                                "minimum": 0.0,
                                "maximum": 1.0
                            }
                        }
                    }
                },
                "total_tokens": {
                    "type": "integer",
                    "minimum": 0
                },
                "reduction_ratio": {
                    "type": "number",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "key_insights": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    }
                }
            }
        })
    }
}